<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Alex LEE&#39;s Blog</title>
  
  
  <link href="http://saili.science/atom.xml" rel="self"/>
  
  <link href="http://saili.science/"/>
  <updated>2019-07-23T04:36:25.000Z</updated>
  <id>http://saili.science/</id>
  
  <author>
    <name>Alex LEE</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Long short-term memory</title>
    <link href="http://saili.science/lstm/"/>
    <id>http://saili.science/lstm/</id>
    <published>2019-07-12T08:35:57.000Z</published>
    <updated>2019-07-23T04:36:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>LSTM算法全称为Long short-term memory，最早由 Sepp Hochreiter和Jürgen Schmidhuber于1997年提出，是一种特定形式的RNN（Recurrent neural network，循环神经网络），而RNN是一系列能够处理序列数据的神经网络的总称。</p><span id="more"></span><h1 id="推导">I. 推导</h1><p>关于lstm，有个非常好的<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">博客</a>。</p><p>前向更新公式为：</p><p><img src="http://vsooda.github.io/assets/lstm/lstm.png" alt="image"></p><p>依照上文的后向传播的推导方式，可以得到， 前向更新，请见代码中<code>#sooda注释</code>部分：</p><p><img src="http://vsooda.github.io/assets/lstm/lstm_forward.png" alt="image"></p><p>后向更新：</p><p><img src="http://vsooda.github.io/assets/lstm/lstm_backward.png" alt="image"></p><p><strong>注意点</strong>:</p><ol style="list-style-type: decimal"><li>通过观察公式1到4， 发现所有的乘机因子为x、h，互相没有依赖，可以并行化。利用向量化进行加速</li><li>IFOG指的是Input，Forget， Output， Cell Gate的计算值。IFOGf是IFOG经过激活函数后的激活值. 并以此为顺序。o-d表示input gate， d-2d表示forget gate， 2d-3d表示output gate， 3d-end 表示cell gate</li><li>WLSTM保存的实际上是所有这些门相对于输入+隐藏层+偏置的权值。</li><li>后向传播从最后一个进行求偏导， 即按照从后向前，按部就班即可，不需要跨步骤考虑</li><li>cache是为了保存后向传播所需要的值</li></ol><p>本文代码可以参考<a href="https://gist.github.com/f93810ce107b0d393cbf.git">gist</a></p><h2 id="反向传播">I.I. 反向传播</h2><p>LSTM的后向推导说是推导，基本上没有一个公式。注重理解。</p><p>cs231上有一篇关于<a href="http://cs231n.github.io/optimization-2/#intuitive">非常好的文章</a>, 讲得非常好。 一个例子： <span class="math display">\[f(x,y) = \frac{x + \sigma(y)}{\sigma(x) + (x+y)^2}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">3</span> <span class="comment"># example values</span></span><br><span class="line">y = -<span class="number">4</span></span><br><span class="line"><span class="comment"># forward pass</span></span><br><span class="line">sigy = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-y)) <span class="comment"># sigmoid in numerator   #(1)</span></span><br><span class="line">num = x + sigy <span class="comment"># numerator                               #(2)</span></span><br><span class="line">sigx = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-x)) <span class="comment"># sigmoid in denominator #(3)</span></span><br><span class="line">xpy = x + y                                              <span class="comment">#(4)</span></span><br><span class="line">xpysqr = xpy**<span class="number">2</span>                                          <span class="comment">#(5)</span></span><br><span class="line">den = sigx + xpysqr <span class="comment"># denominator                        #(6)</span></span><br><span class="line">invden = <span class="number">1.0</span> / den                                       <span class="comment">#(7)</span></span><br><span class="line">f = num * invden <span class="comment"># done!                                 #(8)</span></span><br></pre></td></tr></table></figure><p>对应的后向传播为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># backprop f = num * invden</span></span><br><span class="line">dnum = invden <span class="comment"># gradient on numerator                             #(8)</span></span><br><span class="line">dinvden = num                                                     <span class="comment">#(8)</span></span><br><span class="line"><span class="comment"># backprop invden = 1.0 / den</span></span><br><span class="line">dden = (-<span class="number">1.0</span> / (den**<span class="number">2</span>)) * dinvden                                <span class="comment">#(7)</span></span><br><span class="line"><span class="comment"># backprop den = sigx + xpysqr</span></span><br><span class="line">dsigx = (<span class="number">1</span>) * dden                                                <span class="comment">#(6)</span></span><br><span class="line">dxpysqr = (<span class="number">1</span>) * dden                                              <span class="comment">#(6)</span></span><br><span class="line"><span class="comment"># backprop xpysqr = xpy**2</span></span><br><span class="line">dxpy = (<span class="number">2</span> * xpy) * dxpysqr                                        <span class="comment">#(5)</span></span><br><span class="line"><span class="comment"># backprop xpy = x + y</span></span><br><span class="line">dx = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></span><br><span class="line">dy = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></span><br><span class="line"><span class="comment"># backprop sigx = 1.0 / (1 + math.exp(-x))</span></span><br><span class="line">dx += ((<span class="number">1</span> - sigx) * sigx) * dsigx <span class="comment"># Notice += !! See notes below  #(3)</span></span><br><span class="line"><span class="comment"># backprop num = x + sigy</span></span><br><span class="line">dx += (<span class="number">1</span>) * dnum                                                  <span class="comment">#(2)</span></span><br><span class="line">dsigy = (<span class="number">1</span>) * dnum                                                <span class="comment">#(2)</span></span><br><span class="line"><span class="comment"># backprop sigy = 1.0 / (1 + math.exp(-y))</span></span><br><span class="line">dy += ((<span class="number">1</span> - sigy) * sigy) * dsigy                                 <span class="comment">#(1)</span></span><br><span class="line"><span class="comment"># done! phew</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;LSTM算法全称为Long short-term memory，最早由 Sepp Hochreiter和Jürgen Schmidhuber于1997年提出，是一种特定形式的RNN（Recurrent neural network，循环神经网络），而RNN是一系列能够处理序列数据的神经网络的总称。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
    <category term="LSTM" scheme="http://saili.science/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Python</title>
    <link href="http://saili.science/python/"/>
    <id>http://saili.science/python/</id>
    <published>2019-07-12T08:33:49.000Z</published>
    <updated>2019-09-05T09:17:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>Python是著名的“龟叔”Guido van Rossum在1989年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言。Python就为我们提供了非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容，被形象地称作“内置电池（batteries included）”。用Python开发，许多功能不必从零编写，直接使用现成的即可。除了内置的库外，Python还有大量的第三方库，也就是别人开发的，供你直接使用的东西。当然，如果你开发的代码通过很好的封装，也可以作为第三方库给别人使用。</p><span id="more"></span><blockquote><p>python拥有matplotlib、Numpy、sklearn、keras等大量的库，像pandas、sklearn、matplotlib这些库都是做数据处理、数据分析、数据建模和绘图的库，基本上机器学习中对数据的爬取（scrapy）、对数据的处理和分析（pandas）、对数据的绘图（matplotlib）和对数据的建模（sklearn）在python中全都能找到对应的库来进行处理。</p></blockquote><h1 id="资源">I. 资源</h1><p><a href="https://code-love.com/2019/06/03/49-essential-resources-to-learn-python/#beginner"><strong>Beginner resources</strong></a> for those just starting with programming and Python</p><p><strong><a href="https://code-love.com/2019/06/03/49-essential-resources-to-learn-python/#intermediate">Intermediate resources</a></strong> for those looking to apply the basics of Python knowledge to fields like data science and web development</p><p><a href="https://code-love.com/2019/06/03/49-essential-resources-to-learn-python/#advanced"><strong>Advanced resources</strong></a> for those looking to get into concepts like deep learning and big data with Python</p><p><strong><a href="https://code-love.com/2019/06/03/49-essential-resources-to-learn-python/#exercises">Exercises</a></strong> that help practice and cement Python skills in practice</p><p><a href="https://www.python.org/"><strong>1- Welcome to Python.org</strong></a></p><p>The official Python site offers a good way to get started with the Python ecosystem and to learn Python, including a place to register for upcoming events, and documentation to get started.</p><p><a href="https://learnpythonthehardway.org/book/"><strong>2-Learn Python the Hard Way</strong></a></p><p>An online book with a paid and a free version. The free version goes into an outline of the content and can be a useful to-do list.</p><p><a href="https://realpython.com/python-data-types/"><strong>3-Basic Data Types in Python – Real Python</strong></a></p><p>RealPython dives into the different data types in Python in detail. Learn the difference between floating point and integers, what special characters can be used in Python and more.</p><p><a href="https://realpython.com/run-python-scripts/"><strong>4-How to Run Your Python Scripts – Real Python</strong></a></p><p>This simple intro to Python scripts through the command line and text editors will get you up and running for your first Python experiments — a handy tool to get you started as you learn Python.</p><p><a href="https://www.codecademy.com/learn/learn-python"><strong>5-Python Tutorial: Learn Python For Fre</strong></a><strong><a href="https://www.codecademy.com/learn/learn-python">e</a></strong><a href="https://www.codecademy.com/learn/learn-python"><strong>| Codecademy</strong></a></p><p>Codecademy offers a free interactive course that helps you practice the fundamentals of Python while giving you instant, game-like feedback. A great device for learning Python for those who like to practice their way to expertise.</p><p><a href="https://developers.google.com/edu/python/"><strong>6-Google’s Python Class | Python Education | Google Developers</strong></a></p><p>The official Python development class from Google’s developers. This tutorial is a mix of interactive code snippets that can be copied and run on your end and contextual text. This is a semi-interactive way to learn Python from one of the world’s leading technology companies.</p><p><strong><a href="https://www.learnpython.org/">7-Learn Python – Free Interactive Python Tutorial</a></strong></p><p>This interactive tutorial relies on live code snippets that can be implemented and practiced with. Use this resource as a way to learn interactively with a bit of guidance.</p><p><a href="https://realpython.com/jupyter-notebook-introduction/"><strong>8-Jupyter Notebook: An Introduction – Real Python</strong></a></p><p>Want an easy, intuitive way to access and work with Python functions? Look no further than Jupyter Notebook. It’s much easier to work with than the command line and different cobbled together scripts. It’s the setup I use myself. This tutorial will help you get started on your path to learn Python.</p><p><strong><a href="https://www.w3schools.com/python/">9-Python Tutorial – W3Schools</a></strong></p><p>W3Schools uses the same format they use to teach HTML and others with Python. Practice with interactive and text snippets for different basic functions. Use this tutorial to get a firm grounding in the language and to learn Python.</p><p><strong><a href="https://www.kaggle.com/learn/python">10-Python | Kaggle</a></strong></p><p>Kaggle is a platform which hosts data science and machine learning competitions. Competitors work with datasets and create as accurate of a predictive model as possible. They also offer interactive Python notebooks that help you learn the basics of Python. Choose the daily delivery option to have it become an email course instead.</p><p><strong><a href="https://medium.freecodecamp.org/learning-python-from-zero-to-hero-120ea540b567">11-Learning Python: From Zero to Hero – freeCodeCamp.org</a></strong></p><p>This text-based tutorial aims to summarize all of the basic data and functional concepts in Python. It dives into the versatility of the language by focusing on the object and class portions of the object-oriented part of Python. By the end of it, you should have a neat summary of objects in Python as well as different data types and how to iterate or loop over them.</p><p><strong><a href="https://wiki.python.org/moin/BeginnersGuide">12-BeginnersGuide – Python Wiki</a></strong></p><p>This simple tutorial on the official Python Wiki is chock-full of resources, and even includes a Chinese translation for non-English speakers looking to learn Python.</p><p><strong><a href="https://www.tutorialspoint.com/python/">13-Python Tutorial – Tutorialspoint</a></strong></p><p>Set up in a similar fashion to W3Schools, use Tutorialspoint as an alternative or a refresher for certain functions and sections.</p><p><strong><a href="https://www.quora.com/topic/Python-programming-language-1">14-Python (programming language) – Quora</a></strong></p><p>The Quora community is populated with many technologists that learn Python. This section devoted to Python includes running analysis and pressing questions on the state of Python and its practical application in all sorts of different fields, from data visualization to web development.</p><p><strong><a href="https://dev.to/t/python">15-Python – DEV Community – Dev.to</a></strong></p><p>Dev.to has user-submitted articles and tutorials about Python from developers who are working with it every day. Use these perspectives to help you learn Python.</p><p><strong><a href="https://www.pythonweekly.com/">16-Python Weekly: A Free, Weekly Python E-mail Newsletter</a></strong></p><p>If you’re a fan of weekly newsletters that summarize the latest developments, news, and which curate interesting articles about Python, you’ll be in luck with Python Weekly. I’ve been a subscriber for many months, and I’ve always been pleased with the degree of effort and dedication placed towards highlighting exceptional resources.</p><p><strong><a href="https://realpython.com/python-youtube-channels/">17-The Ultimate List of Python YouTube Channels – Real Python</a></strong></p><p>For those who like to learn by video, this list of Youtube channels can help you learn in your preferred medium.</p><p><strong><a href="https://docs.python-guide.org/">18-The Hitchhiker’s Guide to Python</a></strong></p><p>Unlike the rest of the resources listed above, the Hitchhiker’s guide is much more opinionated and fixated on finding the best way to get set up with Python. Use it as a reference and a way to make sure you’re optimally set up to be using and learning Python.</p><p><strong><a href="https://www.edx.org/learn/python">19-Python: Online Courses from Harvard, MIT, Microsoft | edX</a></strong></p><p>edX uses corporate and academic partners to curate content about Python. The content is often free, but you will have to pay for a verified certificate showing that you have passed a course.</p><p><strong><a href="https://www.coursera.org/courses?query=python">20-Python Courses | Coursera</a></strong></p><p>Coursera’s selection of Python courses can help you get access to credentials and courses from university and corporate providers. If you feel like you need some level of certification, similar to edX, Coursera offers a degree of curation and authentication that may suit those needs.</p><p><strong><a href="https://www.djangoproject.com/start/">21-Getting started with Django | Django</a></strong></p><p>The official Django framework introduction will help you set up so that you can do web development in Python.</p><p><strong><a href="https://www.oreilly.com/learning-paths/learning-path-django/9781788998703/">22-LEARNING PATH: Django: Modern Web Development with Django</a></strong></p><p>This resource from O’Reilly helps fashion a more curated path to learning Django and web development skills in Python.</p><p><strong><a href="https://jvns.ca/blog/2013/12/22/cooking-with-pandas/">23-A pandas cookbook – Julia Evans</a></strong></p><p>I learned how to clean and process data with the Pandas Cookbook. Working with it enabled me to clean data to the level that I needed in order to do machine learning and more.</p><p>It works through an example so you can learn how to filter through, group your data, and perform functions on it — then visualize the data as it needs be. The Pandas library is tailor-built to allow you to clean up data efficiently, and to work to transform it and see trends from an aggregate-level basis (with handy one-line functions such as head() or describe).</p><p>The Pandas cookbook is the perfect intro to it.</p><p><strong><a href="https://stackoverflow.com/questions/tagged/python">24-Newest ‘python’ Questions – Stack Overflow</a></strong></p><p>The Stack Overflow community is filled with pressing questions and tangible solutions. Use it a resource for implementation of Python and your path to learn Python.</p><p><a href="https://www.reddit.com/r/Python/"><strong>25-Python – R</strong></a><strong><a href="https://www.reddit.com/r/Python/">e</a></strong><a href="https://www.reddit.com/r/Python/"><strong>ddit</strong></a></p><p>The Python subreddit offers a bunch of different news articles and tutorials in Python.</p><p><strong><a href="https://www.reddit.com/r/datascience/">26-Data Science – Reddit</a></strong></p><p>The Data Science subreddit offers tons of resources on how to use Python to work with large datasets and process it in interesting ways.</p><p><strong><a href="https://thenextweb.com/dd/2016/04/08/start-using-python-andor-r-data-science-one-best/">27-Data science sexiness: Your guide to Python and R</a></strong></p><p>I wrote this guide for The Next Web in order to distinguish between Python and R and their usages in the data science ecosystem. Since then, Python has pushed ever-forward and taken on many of the libraries that once formed the central basis of R’s strength in data analysis, visualization and exploration, while also welcoming in the cornerstone machine learning libraries that are driving the world. Still, it serves as a useful point of comparison and a list of resources for Python as well.</p><p><strong><a href="https://www.dataquest.io/blog/python-api-tutorial/">28-Data Science Tutorial: Introduction to Using APIs in Python – Dataquest</a></strong></p><p>One essential skill when it comes to working with data is to access the APIs services like Twitter, Reddit and Facebook use to expose certain amounts of data they hold. This tutorial will help walk you through an example with the Reddit API and help you understand the different code responses you’ll get as you query an API.</p><p><strong><a href="https://towardsdatascience.com/introduction-to-data-visualization-in-python-89a54c97fbed">29-Introduction to Data Visualization in Python – Towards Data Science</a></strong></p><p>Once you’re done crunching the data, you need to present it to get insights and share them with others. This guide to data visualization summarizes the data visualization options you have in Python including Pandas, Seaborn and a Python implementation of ggplot.</p><p><strong><a href="https://hackernoon.com/top-python-web-development-frameworks-to-learn-in-2019-21c646a09a9a">30-Top Python Web Development Frameworks to Learn in 2019</a></strong></p><p>If you want a suite of options beyond Django to develop in Python and learn Python for web applications, look no further than this compilation. The Hacker Noon publication will often feature useful resources on Python outside of this article as well. It’s worth a follow.</p><p><a href="https://towardsdatascience.com/beginners-guide-to-machine-learning-with-python-b9ff35bc9c51"><strong>31-Beginner’s Guide to Machine Learning with Python</strong></a></p><p>This text-based tutorial helps introduce people to the basics of machine learning with Python. Towards Data Science, the Medium outlet with the article in question, is an excellent source for machine learning and data science resources.</p><p><strong><a href="https://www.springboard.com/resources/learning-paths/machine-learning-python/">32-Free Machine Learning in Python Course – Springboard</a></strong></p><p>This free learning path from Springboard helps curate what you need to learn and practice machine learning in Python.</p><p><strong><a href="https://www.reddit.com/r/MachineLearning/">33-Machine Learning – Reddit</a></strong></p><p>The Machine Learning subreddit oftentimes focuses on the latest papers and empirical advances. Python implementations of those advances are discussed as well.</p><p><strong><a href="https://www.kdnuggets.com/tag/python">34-Python – KDnuggets</a></strong></p><p>KDNuggets offers advanced content on data science, data analysis and machine learning. Its Python section deals with how to implement these ideas in Python.</p><p><strong><a href="https://www.udemy.com/topic/python/">35-Learn Python – Beginner through Advanced Online Courses – Udemy</a></strong></p><p>Udemy offers a selection of Python courses, with many advanced options to teach you the intricacies of Python. These courses tend to be cheaper than the certified ones, though you’ll want to look carefully at the reviews.</p><p><strong><a href="https://towardsdatascience.com/a-brief-introduction-to-pyspark-ff4284701873">36-A Brief Introduction to PySpark – Towards Data Science</a></strong></p><p>This introduction to PySpark will help you get started with working with more advanced distributed file systems that allow you to deal and work with much larger datasets than is possible under a single system and Pandas.</p><p><strong><a href="https://scikit-learn.org/">37-scikit-learn: machine learning in Python</a></strong></p><p>The default way most data scientists use Python is to try out model ideas with scikit-learn: a simple, optimized implementation of different machine learning models. Learn a bit of machine learning theory then implement and practice with the scikit-learn framework.</p><p><strong><a href="https://towardsdatascience.com/the-next-level-of-data-visualization-in-python-dd6e99039d5e">38-The Next Level of Data Visualization in Python – Towards Data Science</a></strong></p><p>This tutorial walks through more advanced versions of data visualizations and how to implement them, allowing you to take a preview of different advanced ways you can slice your data from correlation heatmaps to scatterplot matricies.</p><p><strong><a href="https://www.coursera.org/learn/machine-learning-with-python">39-Machine Learning with Python | Coursera</a></strong></p><p>Coursera’s selection of courses on machine learning with Python are veryw well-known. This introduction offered with IBM helps to walk you through videos and explanations of machine learning concepts.</p><p><a href="https://www.deeplearning.ai/"><strong>40-Home – deeple</strong></a><strong><a href="https://www.deeplearning.ai/">a</a></strong><a href="https://www.deeplearning.ai/"><strong>rning.ai</strong></a></p><p>Deeplearning.ai is Andrew Ng’s (the famous Stanford professor in AI and founder of Coursera) attempt to bring deep learning to the masses. I ended up finishing all of the courses: they offer certification and are a refreshing mix of both interactive notebooks where you can work with the different concepts and videos from Andrew Ng himself.</p><p><strong><a href="https://www.fast.ai/">41-fast.ai · Making neural nets uncool again</a></strong></p><p>This curated course on deep learning helps break down section-by-section aspects of machine learning. Best of all, it’s completely free. I often use fast.ai as a refresher or a deep dive into a deep learning idea I don’t quite understand.</p><p><strong><a href="https://www.tensorflow.org/tutorials/keras">42-Learn and use machine learning | TensorFlow Core | TensorFlow</a></strong></p><p>This tutorial helps you use the high-level Keras component of TensorFlow and Google cloud infrastructure to do deep learning on a set of fashion images. It’s a great way to learn and practice your deep learning skills.</p><p><a href="https://www.kaggle.com/datasets"><strong>43-Datasets | Kagg</strong></a><strong><a href="https://www.kaggle.com/datasets">l</a></strong><a href="https://www.kaggle.com/datasets"><strong>e</strong></a></p><p>Kaggle offers a variety of datasets with user examples and upvoting to guide you to the most popular datasets. Use the examples and datasets to create your own data analysis, visualization, or machine learning model.</p><p><strong><a href="https://www.practicepython.org/">44-Practice Python</a></strong></p><p>Practice Python has a bunch of beginner exercises that can help you ease into using Python and practicing it. Use this as an initial warmup exercise before you tackle different projects and exercises.</p><p><strong><a href="https://www.w3schools.com/python/python_exercises.asp">45-Python Exercises – W3Schools</a></strong></p><p>The Python exercises on W3Schools follow the sections in their tutorials, and allow you to get some interactive practice with Python (though the exercises are in practice very simple).</p><p><strong><a href="https://www.hackerrank.com/domains/python">46-Solve Python | HackerRank</a></strong></p><p>HackerRank offers a bunch of exercises that require you to solve without any context. It’s the best way to practice different functions and outputs in Python in isolation (though you’ll still want to do different projects to be able to cement your Python skill.) You’ll earn points and badges as you complete more challenges. This certainly motivates me to learn more. A very useful sandbox for you to learn Python with.</p><p><strong><a href="https://projecteuler.net/">47-Project Euler: About</a></strong></p><p>Project Euler offers a variety of ever-harder programming challenges that aim to test whether you can solve mathematical problems with Python. Use it to practice your mathematical reasoning and your Pythonic abilities.</p><p><strong><a href="https://docs.djangoproject.com/en/2.2/intro/tutorial01/">48-Writing your first Django app, part 1 | Django documentation | Django</a></strong></p><p>This documentation helps you get on the ground with your first Django app, allowing you to use Python to get something up on the web. Once you’ve started with it, you can build anything you want.</p><p><strong><a href="https://www.edureka.co/blog/interview-questions/python-interview-questions/">49-Top 100 Python Interview Questions &amp; Answers For 2019 | Edureka</a></strong></p><p>Should you ever be in an interview where your Python skills are at question, this list of interview questions will help as a useful reminder and refresher and a good way for you to practice and cement different Python concepts.</p><p>50-<a href="https://www.comparitech.com/blog/information-security/hacking-python-courses-online/">6 best online courses for ethical hackers</a></p><p>Ethical hackers play an important role in organizations by finding and fixing vulnerabilities in systems and applications. Python is a high-level programming language that’s ideal for security professionals as it’s easy to learn and lets you create functional programs with a limited amount of code.</p><h1 id="实例">II. 实例</h1><h2 id="语法">II.I. 语法</h2><p>爬虫：requests、scrapy、selenium、beautifulSoup，这些库都是写网络爬虫需要使用到的，好好掌握这些东西，数据就有了。</p><p>数据处理：Numpy、scipy、pandas、matplotlib，这些库分别可以进行矩阵计算、科学计算、数据处理、绘图等操作，有了这些库，你就可以一步步开始把数据处理成你需要的格式。</p><p>建模：nltk、keras、sklearn，这些库主要是用于自然语言处理、深度学习和机器学习的，把这些用好了，你的模型就构建出来了。</p><p>Web开发：django、flask、tornado，这些库搞明白了，你web开发也就搞定了。</p><h3 id="requests">II.I.I. requests</h3><p>优雅简单的 HTTP 模块。</p><h3 id="beautifulsoup">II.I.II. BeautifulSoup</h3><p>很好用的 HTML/XML 解析器。</p><h3 id="json">II.I.III. json</h3><p>JSON 编码解码器。</p><p>应用举例：</p><ul><li>格式化 JSON 文件</li></ul><p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m json.tool src.json &gt; dst.json</span><br></pre></td></tr></table></figure></p><p>在 Vim 里格式化 JSON：</p><p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:%!python -m json.tool</span><br></pre></td></tr></table></figure></p><h3 id="cgihttpserver">II.I.IV. CGIHTTPServer</h3><p>简单实用的 HTTP 服务器。</p><p>应用举例：</p><ul><li>运行一个简易的 HTTP 服务器</li></ul><p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m CGIHTTPServer 80</span><br></pre></td></tr></table></figure></p><h3 id="base64">II.I.V. base64</h3><p>方便地进行 base64 编解码的模块。</p><p>应用举例：</p><ul><li>解码 base64</li></ul><p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> aGVsbG93b3JsZA== | python -m <span class="built_in">base64</span> -d</span><br></pre></td></tr></table></figure></p><p>则能看到输出</p><p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helloworld</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Python是著名的“龟叔”Guido van Rossum在1989年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言。Python就为我们提供了非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容，被形象地称作“内置电池（batteries included）”。用Python开发，许多功能不必从零编写，直接使用现成的即可。除了内置的库外，Python还有大量的第三方库，也就是别人开发的，供你直接使用的东西。当然，如果你开发的代码通过很好的封装，也可以作为第三方库给别人使用。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://saili.science/categories/Programming/"/>
    
    <category term="Python" scheme="http://saili.science/categories/Programming/Python/"/>
    
    
    <category term="Python" scheme="http://saili.science/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>科技论文词汇与语法</title>
    <link href="http://saili.science/vocabulary/"/>
    <id>http://saili.science/vocabulary/</id>
    <published>2019-05-05T03:03:27.000Z</published>
    <updated>2019-05-05T03:17:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>虽然大家的学科领域不同，但起承转合的论文写作逻辑套路是共通的，掌握了这些高频词汇和短语，了解了提示文章逻辑的连接词，又掌握了文章论述中惯用的表达方式，一定能帮您在SCI论文写作过程中更轻松容易，提高写作效率。</p><span id="more"></span><h1 id="i.e.等">I. i.e.等</h1><blockquote><p><a href="https://zhuanlan.zhihu.com/p/63640148">论文常用词汇i.e.，e.g.，etc.，viz.，et al.的前世今生</a></p></blockquote><p>i.e.是id est（“that is” , &quot;in other words&quot;。进一步解释用，意为：也就是）的缩写。目的是用来进一步解释前面所说的观点（不像后文的e.g.那样引入实例来形象化），意思是“那就是说，换句话说”。它后面最好紧跟着一个逗号，再跟一个解释。(看大量例句，发现有些句子的确省略了逗号，见例句1和例句2）</p><blockquote><p>例句1：Each of these items are actionable, i. e. you can actually do them.<br>例句2：The film is only open to adults, i.e. people over 18.<br>例句3：And you have to cross reference this time/effort analysis to the results (i.e., the bugs) that the effort yielded.</p></blockquote><p>e.g.是exempli gratia（&quot;for example; for instance;such as&quot;。举例用，意为：例如）的缩写，其目的用若干例子来让前面说法更具体，更易感知。在使用中，最好把e.g.连同它的例子放在括号中，如例句2。</p><blockquote><p>例句1: I like sports, e.g., football.<br>例句2：I like most of sports activities (e.g., football).</p></blockquote><p>i.e.和e.g.的区别：</p><blockquote><p>例句1：I like to eat boardwalk food, i.e., funnel cake and french fries.<br>例句2：I like to eat boardwalk food, e.g., funnel cake and french fries.</p></blockquote><p>例句1表示只有 funnel cake and french fries这两种boardwalk食物，而且这两种我都喜欢。例句2表示我喜欢boardwalk食物，比如 funnel cake and french fries；但是诸如snow cones and corn dogs等其他类型，我也可能喜欢。</p><p>etc.是et cetera(“and so forth; and the others; and other things; and the rest; and so on&quot;。举例用，意为：等等)的缩写。它放在列表的最后，表示前面的例子还没列举完，最后加个词“等等”。</p><p>etc.前面要有逗号。一般不要在e.g.的列表最后用etc( 在including后的列表后也不宜使用etc)。这是因为 e.g. 表示泛泛的举几个例子，并没有囊括所有的实例，其中就已经包含“等等”，如果再加一个 etc. 就多余了。</p><blockquote><p>例句1: I need to go to the store and buy some pie, milk, cheese, etc.</p></blockquote><p>viz.是videlicet（ &quot;namely&quot;, &quot;towit&quot;, &quot;precisely&quot;, &quot;that is to say&quot;。进一步解释用，意为：即）的缩写，与e.g.不同，viz位于同位列表之前，要把它前面单词所包含的项目全部列出。</p><blockquote><p>例句1：The school offers two modules in Teaching English as a Foreign Language, viz. Principles and Methods of Language Teaching and Applied Linguistics.（该校提供两个模块用于英语作为外语的教学，即语言教学的原理方法和应用语言学。）<br>例句2: In this paper, a new TDNN architecture with two input variable, viz. wave form and its phase difference, is developed to reduce the grain noise.（本文提出了一种新的TDNN结构用于降低粗晶材料结构噪声，该结构具有波形及其相位差组成的双变量输入。）</p></blockquote><p>et al.是et alia（&quot;and others; and co-workers&quot;。在引用文献作者时用，意为:等其他人）的缩写。它几乎都是在列文献作者时使用，即把主要作者列出后，其它作者全放在et al. 里面。</p><p>et al.的前面不要逗号。人的场合用et al，而无生命的场合用etc.(et cetera)。</p><blockquote><p>例句1: These results agree with the ones published by Pelon et al. (2002).<br>例句2: Clegg et al. (1995) explain that in the electronics industry linear-programming models can be used to analyse the viability of the recovered parts in remanufacturing.（克莱格等人（1995）解释说，电子行业的线性规划模型可以用来分析在再制造过程中回收零部件的可行性。）</p></blockquote><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;虽然大家的学科领域不同，但起承转合的论文写作逻辑套路是共通的，掌握了这些高频词汇和短语，了解了提示文章逻辑的连接词，又掌握了文章论述中惯用的表达方式，一定能帮您在SCI论文写作过程中更轻松容易，提高写作效率。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="论文写作" scheme="http://saili.science/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>国家自然科学基金</title>
    <link href="http://saili.science/nsfc/"/>
    <id>http://saili.science/nsfc/</id>
    <published>2018-12-03T09:01:56.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.nsfc.gov.cn/">国家自然科学基金</a>是20世纪80年代初，为推动我国科技体制改革，变革科研经费拨款方式，中国科学院89位院士（学部委员）致函党中央、国务院建议的。自然科学基金坚持支持基础研究，逐渐形成和发展了由研究项目、人才项目和环境条件项目三大系列组成的资助格局。</p><span id="more"></span><h1 id="基金介绍">I. 基金介绍</h1><p>基金委项目允许失败，需要把看不见的东西变成看得见的东西，虽然是理论，需要添加一个应用背景，从应用背景中升华思想。着重理论创新。</p><p>其中基金申请书相当于博士论文的开题报告，函评则需要体现创新点，年度报告对应于博士论文的中期进展报告。</p><h1 id="基金类型">II. 基金类型</h1><p>国家自然科学基金委员会公布了集中接收申请的项目类型包括：面上项目、重点项目、部分重大项目、部分重大研究计划项目、青年科学基金项目、优秀青年科学基金项目、国家杰出青年科学基金项目、创新研究群体项目、地区科学基金项目、海外及港澳学者合作研究基金项目、部分联合基金项目、国家重大科研仪器研制项目（自由申请）、数学天元基金项目、重点国际（地区）合作研究项目和外国青年学者研究基金项目等。通过亚类说明、附注说明还可将一些资助类别进一步细化。所有这些资助类别各有侧重，相互补充，共同构成当前的自然科学基金资助体系。</p><h2 id="青年科学基金项目">II.I. 青年科学基金项目</h2><p>青年基金一个人一辈子只能获批一次，项目3年，总共给25万左右的经费/资助强度。</p><h2 id="面上项目">II.II. 面上项目</h2><p>面上项目，要高级职称（副教授、教授）才可以申请。资助强度80万左右（我都说的是理工科实验性的课题），时间4年。面上是大多数教授主要申请的。</p><h2 id="重点项目">II.III. 重点项目</h2><h1 id="基金申请">III. 基金申请</h1><ul><li><a href="http://fund.sciencenet.cn/?id=781">基金申请-科学网</a>，<a href="http://muchong.com/html/f234.html">基金申请-小木虫</a></li><li><a href="https://isisn.nsfc.gov.cn/egrantindex/funcindex/prjsearch-list#">项目综合检索|国家自然科学基金委员会</a>，<a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=45&amp;do=blog&amp;id=1129759">2018国家自然基金重点项目资助情况汇总</a>，<a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=45&amp;do=blog&amp;id=1130045">2018基金完整数据查询分析+资助统计系列报告</a>，<a href="https://zhuanlan.zhihu.com/p/45283337">2019国家自然基金最新政策</a></li><li><p><a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=69051&amp;do=blog&amp;id=1148205">国家自然科学基金申请指导与技巧-徐长庆</a>，<a href="http://blog.sciencenet.cn/blog-52727-1060219.html">申请国家自然科学基金项目的一点体会</a>，<a href="http://zmtt.bao.ac.cn/zatan/NSFCapplication.html">一步一步教你如何写国家基金申请书</a>，<a href="http://blog.sciencenet.cn/blog-63255-1091734.html">国家自然科学基金申请书的若干建议</a>，<a href="https://mp.weixin.qq.com/s/XnKIaF5NdWAxwSoxJjY3lg">百份国自然标书的专家评审意见</a></p></li><li>准备自然基金申请材料过程是一个很好的充电过程。</li><li>自然基金撰写过程也是思考下一年度研究生们研究课题的很好过程。思考这个领域哪些东西是他人没有做过的，哪些东西又是具有创新意义的。我们要思考采用什么样的高科技手段去解决哪些重要的未知科学问题。与此同时，我们还需要思考这些研究内容是否可以顺利完成。</li><li><p>撰写自然基金过程也是深入学习、了解国家科技政策最新发展趋势的一个好机会。清晰地知道国家未来评价学术科研人员的走向。</p></li></ul><h2 id="政策分析">III.I. 政策分析</h2><p>申请者在准备之前，</p><ul><li>要重点关注《项目指南》中的“申请须知”和“限项规定”。</li><li>要认真阅读并准确解读《项目指南》中与申请内容有关的学部和科学处的论述部分，尤其是学科的资助范围，最好对前几年《项目指南》的相关部分都有所了解，以便比较全面地了解申请者所在学科的资助范围、资助特点等信息。</li><li>应仔细阅读并准确理解《基金条例》、《基金管理办法》、《基金经费管理办法》中的相关内容，重点了解包括各类基金的申请x条件、限项要求、推荐要求、经费预算要求等，尤其是管理费、国际合作与交流费以及劳务费的比例和使用范围，切实做到心中有数。</li></ul><h2 id="流程">III.II. 流程</h2><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fxfp88lsv1j20k00f0dhe.jpg"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/083255mazh7cir7xyy3x9s.png"></p><ol style="list-style-type: decimal"><li>3月份申请书交上去，然后基金委会分发给领域内相关专家审查，然后评分，决定是否进入审查会议。上会的本子再有若干比例被刷掉，剩下的获得资助，年底的时候资助决定下来（青年基金各学科资助率都是大概20%）。</li><li>申请书一般是从4月下旬开始陆陆续续送到评审专家手中，进入到<strong>专家评审</strong>的环节。杰青，优青和重点项目是六位评委，面上，青年和地区基金五位评委。<ul><li>审稿专家：获得过基金并在基金委的系统中登记了信息的人，并实时更新个人在专家库的信息。</li><li>基金委的综合局根据申请书的关键词，排除师生关系、当年度是否申请基金以及本单位等回避因素后，从专家库中随机挑选的。</li></ul></li><li>量化评价：A优、B良、C中，D差，同时还要提出资助意见：A优先资助，B同意资助和不给资助。除了这些意见外，每个评委都会要求写成书面意见。基金委对于不负责的评审意见，特别是哪种字数少于20个字的意见，会将这类评委列入黑名单，今后不再劳其大驾。<ul><li>客观地评判每一份申请书。</li><li>有些本子连续几年都没有拿到，一定要冷静下来，在自己身上找原因。</li></ul></li><li>五月下旬到六月中旬，评审意见陆续返回到基金委。这两年又多了个网评的环节，基金委收到的同行专家的评价意见后又选择一些专家进行网络评审。</li><li>基金委根据评审意见，提出是否进入会评（二评）的名单。<ul><li>基金委的各学科处按照当年的指标，提出推荐项目数（正选项目）和一定数量的候选项目数。选择的依据仍然是同行评价的意见。</li><li>申请书网评意见至少为三份，最多四份。排名前12%（大体如此，分成两种情况）的为A类项目，12%到35%的为B类项目，其他为C类项目。项目分级和是否上会讨论，由计算机自动给出，并没有人为干预。</li><li>所有的项目根据网络评审意见自动分级，根据每一个项目的评审意见，给予相应分值。比如，优先资助4分，资助3分，不予资助-3分，最后按照公式自动计算每一个项目的得分。综合评分=（A<em>4+B</em>3+C<em>2+D</em>1）/ 评议份数，资助建议=（A<em>4+B</em>2）/ 评议份数</li></ul></li><li>基金委选择专家组成，进行各学科的会评（二评）。所有的项目都要进行表决，表决过半的项目才能给予资助。<ul><li>会评的重点就是决定哪些A类项目有没有异常，哪些B类项目应该得到资助。</li><li>如果有会评专家认为每个落选的项目非常好，那么他也是可以提出将这份申请书上会评议的。这个时候，他需要写出意见，并约另外一名专家推荐并上网公示。 <img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fxfpp54etsj20rs0kujua.jpg" alt="函评结果和获得资助的相关性"></li><li>在当年有三位评委的时候，没有不同意资助的本子（3A、2A1B、1A2B、3B）百分之百要推荐上会的。评审意见有较大冲突，但正面意见为主的本子（2A1C）的本子也基本上是百分之百的被推荐上会了。有一些不好也不坏的本子（1A1B1C）也有机会被推荐上会。从评审结果看，绝大部分3A的本子能够拿到项目，2A1C的本子拿到项目的比例也不小，相反是平庸的本子（3B）在评审中最危险，仅有70%的本子能够拿到项目。</li></ul></li></ol><p>面上项目：总分大于5.5分的项目上会,上会率一般为30%。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20190529182456.png"></p><p>青年项目：总分大于5分的项目上会,上会率一般为30%</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20190529182520.png"></p><p>会评结果不容乐观的5种情况<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>：</p><ol style="list-style-type: decimal"><li>个别创新点重复，如果有意见明确指出了可能与申请书创新点重复的文献，会评一般难以通过；</li><li>申请人在某些可疑的杂志上刊登论文，被网评意见指出，基本不会通过。所以建议朋友们投稿时一定要谨慎，不要投机取巧。</li><li>有些创新点被指出不可行，并给出明确意见，不会通过。如果评审给出一些非常专业而具体的意见，比如明确指出了技术路线的不可行，只要出现这样的很硬的负面意见，该项目即便打分较高，也可能不予资助。</li><li>争议比较大，多数网评中的负面意见具体详细，一般不会通过。有些项目虽然网评分数较高，有上会资格，但如果出现集中具体的负面意见，也可能得不到资助。</li><li>部分内容缺失，如技术路线、可行性分析等缺失情况严重。很多基金申请人的基础较好，课题也是比较热门的课题，但是申请书撰写的不够严谨，缺少必要部分，特别是技术路线不详细，可行性论证不扎实，这些都算是申请书的硬伤，如果出现这种情况，得不到资助的概率就偏大。</li></ol><h1 id="基金检索">IV. 基金检索</h1><p>国家自然科学基金官网提供了 <a href="http://output.nsfc.gov.cn/projectQuery">结题报告检索</a> 的功能，可以结合 <a href="https://github.com/Rhilip/NSFC_conclusion_downloader/releases">NSFC_conclusion_downloader</a> 实现PDF文件的下载。</p><ol style="list-style-type: decimal"><li>下载 <code>nsfc_conclusion_downloader.zip</code>，并解压。</li><li>在 <a href="https://www.medsci.cn/sci/nsfc.do">国家自然科学基金查询系统-medsci</a> 获取项目信息，在 <a href="http://output.nsfc.gov.cn/projectQuery">结题报告检索</a> 页面检索得到对应的项目，并复制相关项目网址。</li><li>复制到软件地址栏，点击下载，完成后自动打开生成的PDF文件（存储在本程序放置的根目录）。</li></ol><h1 id="基金书写">V. 基金书写</h1><blockquote><p><a href="https://mp.weixin.qq.com/s/DDJ5xl-cQdgJkBBrZL2uoA">高质量国基金申请书的必备要素</a>，<a href="https://mp.weixin.qq.com/s/-4N0t6kEhAmwqJgOnvSvgg">2021年国家自然科学基金NSFC标书撰写要点详述</a></p></blockquote><p>用以自己熟悉的方式，说清楚四个问题，最为关键。</p><ul><li>1）为什么要做这个事情，这就是<strong>立项依据</strong>；</li><li>2）做些什么事情可以解决你提出来的科学问题，实现预期目标，这就是<strong>研究内容</strong>；</li><li>3）如何去做这些事情，这就是<strong>技术路线和研究方法</strong>；</li><li>4）<strong>为什么我能做这个事情</strong>，这就是<strong>研究基础</strong>。</li></ul><p>一个好的申请书必须在上述四者间建立一条<strong>完整的逻辑链</strong>，做到环环相扣。研究内容支撑立项依据，研究方法和技术路线服务于研究内容，已有的基础保证项目成功的可靠性。</p><p>总体原则：</p><ul><li>消除所有的低级错误。</li><li>通读性。专有名词和概念解释清楚，让大同行看懂。小同行认为有水平。<ul><li>通读性。一方面要尽量少用那些特别难理解的专业术语，一方面要努力拓宽自身的专业知识面，使自己能在更宽的学术视野中描绘自己研究工作的科学意义，以更好地说服那些大同行。</li></ul></li><li>一定还要注意各部分之间的<strong>合理衔接</strong>。科学问题、研究内容、技术路线、研究基础、研究队伍和经费预算等各方面，应当思路连贯、互相支撑。例如，研究内容中欲开展某方面的工作，在技术路线中应有相应的具体实施方案（使用仪器设备、实验流程和达到的技术指标等），而在研究队伍中，就应有相关的人员分工该项工作，而经费预算中也需列入相关的开支。</li><li>立项依据和研究方案中涉及到的要素、核心内涵及其价值必须给予足够<strong>坚实和充分的论述</strong>。在提出新思路、新想法之后，论述过程演进的逻辑线必须是连续的，不能有破点，论据必须是坚固的，不能有断点；方案的制订能够体现针对性、整体性、完整性，思路上的独到性和可行性，还要特别注意技术上的细节是否能够支撑得起整个方案，不要因小失大而留下遗憾。</li><li>可以利用“其他需要说明的问题”这个栏目答复一下评审人的评审意见，但是这个答复必须是心平气和，有理有据的。</li></ul><h2 id="选题">V.I. 选题</h2><p>申请基金之前，申请人需得把大量时间花在课题调研、构思和学术积累上。</p><blockquote><p><a href="https://mp.weixin.qq.com/s/k_Ott0nqTfxcrtrUbVYk6A">国家自然科学基金委各科学部优先发展领域及主要研究方向-2020</a></p></blockquote><p>如何选题，选择什么题目，开展什么研究是来自科研人员自己的学术积累、经验和兴趣，要靠自己通过大量阅读文献结合自己从研究去领悟和选择。千万注意要避开“大牛的研究方向”，一来容易撞车，二来在比较中落后(原因自明)。再者，选题属于当前的热点，有一定积累为佳。</p><ul><li>务必认真阅读基金申请指南。</li><li>查阅以往资助的《资助项目汇编》，避免重复。</li><li>没有人做过的课题不能做为立项的依据，但NSFC资助的项目必须是国际上没人做过的，而不是国内空白。</li><li><font color="red">提倡面向“小而精”的科学问题</font>。建议理顺下思路，找出个可行的、小的、且是瓶颈的科学问题开展研究，方能说服评审专家。</li><li>选题不能太窄，太小，自然科学的选题要有一定科学意义，要尽可能地去<strong>接近国际前沿</strong>，要有一定的挑战性，要敢于去选择那些有一定难度和关注度比较大的科学问题去研究。</li><li>选题最好以问题为导向，不要以技术为导向，找到问题了，课题就找到了。好课题是对学科深刻理解的条件下产生的，大量翻阅文献吧，汲取知识的同时千万别忘了思考，你发现别人存在漏洞的时候，好课题就离你不远了。</li><li>一定要到NSFC检索一下类似课题的历年资助情况，太多、太少都不好，最好是最近二年逐渐增加的资助领域。</li><li>问自己以下几个问题：1）拟申请项目的核心科学问题是什么？2）解决这个问题的意义何在？3）你要做的问题，是否有同行（国内外）在做？如果在做，做到什么程度，已经解决什么样的问题，还有什么问题没有解决？</li><li>有针对性的准备工作：<ul><li>1）做一点预研究，试试自己想法的可行性，找找实验的难点，获得一点初步的结果，这样在基金的申请书中对问题的阐述会更加深刻和准确。</li><li>2）收集必要的材料和样品，</li><li>3）学术思想和科学假说是基金申请书的核心和闪光点，如果能够在申请基金前写一篇综述文章，把自己的假说和观点也展示出来，然后在申请书中引用这篇文献，这样你的观点更容易被评审人所接受。</li></ul></li></ul><h2 id="简表部分">V.II. 简表部分</h2><p>题目、中英文摘要、申请人及团队，就是你给评审人的第一印象。</p><ul><li>项目名称要确切、醒目，主题明了，让别人一看题目就能明了你干哪方面的具体研究，对象是什么，用什么研究方法，解决什么具体问题。<ul><li>申请题目要力求简短，有学术高度且适度。将关键词进行有序和合乎逻辑的组合，用最少的文字表达最重要和最清晰的信息。</li><li>没有必要在题目中加上基础研究或应用基础研究等修饰字样，</li></ul></li><li>报送学科要准确，勿将学科代码当指南。<ul><li>如果你的申请内容涉及多个学科，你就要比较各相关学科的项目指南，看一看你的研究重点与哪个学科更接近</li></ul></li><li>项目属性应明确，科学基金不支持应用开发。</li><li><strong>务必写好400个字摘要</strong>，项目的科学意义（立项依据，科学问题，150字）；研究内容与拟采用的方法（150字）；预期结果（100字）。<ul><li>摘要通常有7个句子，分别描述不同的内容。其中1个句子描述背景、1个句子描述研究现状、1-2个句子描述科学问题、2-3个句子描述研究内容及技术方法、1个句子描述结果、结论及意义（落脚到特定对象）。即针对特定对象，体现特色。</li><li>让别人可以看明白申请项目研究的对象是什么，采用什么研究方法，准备解决什么关键性的科学问题等等。高度浓缩地回答为什么、做什么、怎么做及本工作意义等问题。</li><li>不建议使用语气连接词，多使用定语，逻辑紧密，一气呵成。</li></ul></li><li>通常5个关键词中可能有2（或3）个描述科学问题，1个描述研究内容，1个描述技术方法，1个描述预期结果和意义。另外，关键词要依照关键词的内涵及逻辑关系进行排列。</li><li>项目组主要成员。<ul><li>要注意培养自己较为稳定的科研团队，为施展你的科研才华奠定人力资源基础。一个好的科研团队应该是：除了研究生，其他成员具有较好的学术经历（基础）和一定成果显示；学科结构合理（尤其对于涉及多学科交叉团队）；年龄结构合理（以中青年为主）；学缘结构较好。</li><li>尽早建立研究团队，就相关问题开始合作研究，并商议确定主要研究课题。</li><li>成员避免出现超项申请问题</li><li>研究队伍的组成合理。组成不能太少，<strong>只谈科研的身份</strong>，每项内容都应该有相关研究背景的人员负责。</li><li>在基金申请书完成之后，应该将申请书送给每位参与人阅读，获得项目组成员的认可，同时要求每位项目组成员在申请书上<strong>亲笔签名</strong>。实在是拿不准电话请教基金委的管理人员。</li></ul></li></ul><h2 id="科学问题属性">V.III. 科学问题属性</h2><blockquote><p><a href="https://mp.weixin.qq.com/s/7chuiIlS3m8ULZyQXG44Qw">国家自然科学基金委发布八大学部四类科学问题83个典型案例</a>，<a href="https://mp.weixin.qq.com/s/GDMHAUgakfDYmgt3ITbKRQ">国家自然科学基金委更新四类科学问题属性案例（2021版）</a></p></blockquote><blockquote><p>摘录于火行的文章“<a href="https://mp.weixin.qq.com/s/DoccQKi7JHg7JEpJ2G_GAw">到底800字科学问题属性怎么写？</a>”</p></blockquote><p>科学问题属性指的是：“鼓励探索，突出原创”、“聚焦前沿，独辟蹊径”、“需求牵引，突破瓶颈”、“共性导向，交叉共融” 这四个属性。同时这个四点属性，更像是：（1）纯原创 （2）再创新 （3）应用型（4）跨界型。</p><p>第一类（鼓励探索，突出原创）：那么就说明相关的课题是纯原创，目前均未做过或实现过，重点落在从无到有表述上；</p><p>第二类（聚焦前沿、独辟蹊径）：这块要说明当下前沿研究有哪些欠缺或者需要优化，申请人的想法比已有的突破、拓展在哪里；</p><p>第三类（需求牵引，突破瓶颈）：这个要着重说明研究内容符合实际国家需求且应具体产业化前景，但目前的效能并未得到解决，而申请人的研究成果可能会有效地促进相关产业、技术迭代等；</p><p>第四类（共性导向，交叉融通）：表述上要着重阐明自己的研究是在相关学科内的理念、技术下通过一定程度的交叉，解决共同的需求导向问题，且相应的融合会促进知识体系的发展与延伸。</p><p>假设项目研究是在再创新，是对于相应技术的优化创新，同时我的文章代表作，相应的研究基础，支撑申报的材料都更偏向于基础研究类型，这里比较符合选第二个。在回答的具体操作上，要阐明：为什么我觉得这个课题是前沿的，你的依据什么，与最前沿的相关性多大，同时也要着重说明自己的研究内容是偏应用还是基础。</p><p>举例，项目属性适合“聚焦前沿、独辟蹊径”，假设研究内容是：机器翻译（下列分布、字数，来源等仅供参考）</p><p>（1）简明扼要的讲清研究主体前沿、热点、已有研究成果（国内外研究摘选100字左右，这部分是为了后边凸显你的再创新）； （2）然后对比性的论述目前研究的欠缺或者亟待优化的点：技术、对象等？（摘选创新点，100字左右）； （3）具体的实现的意义：相应的算法、技术识别仍有提升空间包括但不限于优化、缺陷、拓展等 （着重落笔，整合技术路线、可行性、关键科学问题等；备注：需求产业化的，要说明对于实际产业界有什么预期经济效益，400字左右）； （4）当前的工作，与自己的背景是偏向于基础研究还是应用需求（这部分务必点明一下，尽可能的说清自己的情况，这部分依据自己的个人简历背景，支撑材料情况，50字左右）； （5）总结性概况，你解决了什么科学问题，点一下属性(70字左右）。</p><h2 id="立项依据与研究内容">V.IV. 立项依据与研究内容</h2><p>凝练、明确的、新颖的、吸引人的、科学的、有逻辑地、技术路线的清晰性、排列的规整性、布局的合理性</p><h3 id="立项依据">V.IV.I. 立项依据</h3><blockquote><p><a href="http://blog.sciencenet.cn/blog-38899-1088051.html">科学基金申请：如何写好立项依据和研究方案</a></p></blockquote><p>项目的立项依据包括研究意义、国内外研究现状及发展动态分析，需结合科学研究发展趋势来论述科学意义；或结合国民经济和社会发展中迫切需要解决的关键科技问题来论述其应用前景。附主要参考文献目录。</p><p>研究者需明确拟开展的研究究竟是个什么样的问题（what），为什么要研究它（why），从何处入手（where），有什么对策、如何破解（how），谁来做最合适（who）。使审稿人明确课题的科学问题、研究假说、研究思路及科学意义，并赞同选题的创新性、科学性、可行性和重要性。</p><ol style="list-style-type: decimal"><li>为什么值得做？研究意义，应用价值和前景。以说明这个科学问题是必须突破而尚没有解决的瓶颈问题为论证的主线。是否会对所在领域做出新的贡献？是否会增进所在领域的知识？是否有明确的研究目的和长远的目标？<ul><li>简要地以科学研究发展和国民经济、社会发展为背景，点出本课题的理论价值和潜在的应用价值。</li><li>要学会勤于观察和思考，深度挖掘藏在表象背后的本质，发现和理解事物之间的关联和区别，</li><li>有效凸显：① 领域/行业重要性—&gt;② 现状及问题—&gt;③ 解决以上问题的意义这三点一线的脉络，需高度凝练。在意义上建议重点突出：① 社会效应、② 学科发展、③ 方向引领以及④ 科学普适贡献等方面；</li></ul></li><li>别人做的如何？围绕针对的对象，国内外研究现状、发展动态、及分析，提出问题。<ul><li>以问题为导向，高屋建瓴且精炼地归纳已有的发现和贡献（已解决的问题，既往研究背景），指出研究的缺失以及尚未解决的关键科学问题（本项目的科学研究目标）。<ul><li>认真调研研究方向的历史沿革，客观认真地评述同行成果（汇总前言、评论内容），并在此基础上提出项目选题。</li><li>国外动态，国内研究情况，应包括申请者自己的研究工作，最好事先发表相应的综述文章。</li><li>特别是<strong>近五年</strong>的国内外研究进展，突出前沿和热点</li><li>建议分成若干个方面分别阐述，做到重点突出，归纳而不罗列。</li><li>引用有争议的材料，务必确保对产生该争议的原因有所了解。并要直接阐明观点的不同之处。</li></ul></li><li>展开论述申请人是如何认识和理解这个问题的（有什么理由做这个）。把研究的问题所涉及因素的本质和因素之间的关系梳理清楚。</li></ul></li><li>你要解决哪个科学问题，有何创新。<ul><li>解决该问题的新想法，准备用什么方法研究什么、有望解决什么问题、有什么重要的意义和价值。落脚到对象和普适性，对应于研究内容。<ul><li>研究思路是要陈述申请者解决科学问题和验证研究假说的研究线路框架，体现出申请者对如何解决科学问题的一个致密的思考过程。</li></ul></li></ul></li><li>为什么我们最适合做？证明自己是项目的最佳实施者<ul><li>简述申请人团队的研究优势，对于一些竞争性项目这一点尤其重要，似乎“非我莫属”，或者我的团队是目前这个方向做的相对最好。</li><li>申请人在这个领域做过哪些工作？取得什么重要结果？<ul><li>如果我们把一个项目的整个研究内容划作100%，前期工作基础应该要完成了30-50%。</li><li>论述预研的来龙去脉，如何思考的，并在预实验的基础上提出“研究假说”。不但提出的科研思路更可行，而且研究方案更符合实际、更形象，也显得申请人更有自信。</li><li>相关的<strong>前期工作</strong>，展示出初步的实验数据、图表。可视化的表达会吸引评阅人的眼球。</li></ul></li></ul></li><li>参考文献。<ul><li>直接相关的文献、国内同行的文献、<strong>权威性文献</strong>、<strong>前沿性文献</strong>、<strong>顶级期刊</strong>。中文文献占比1/3。</li><li>考虑是否每个观点都值得引用，考虑是否每篇论文都需要被引用</li><li>说明背景时引用少量的综述</li><li>众人皆知的事实没有必要做大量的引证，与项目相关性不大的话题没有必要做大量的引证，</li></ul></li></ol><p>立项依据要紧紧围绕着<strong>关键科学问题的提出、分析和解决</strong>的主线进行写作。从简要的研究背景介绍，自然的过渡到项目要解决的重要科学问题，以及针对该科学问题开展的前期工作基础是否支持科学问题可行，在此基础上还存在哪些小的科学问题（或者说需要进一步深入的研究细节）需要提出本项目继续开展研究。</p><p><strong>按照研究内容设置段落数</strong>，如果有3个内容，立项依据有5段。第一段，总括表述研究的意义，2-4段分别对应3个研究内容进行阐述，5段总结提出科学问题/科学假设。</p><p>通过已有的文献和自己的想法结合，引出研究思路。比如，某因子A对某通路B的影响，可能是直接的，也可能是涉及中间某些其他因子C，从而起作用。需要理顺的是：① A与B的研究现状如何，和自己的研究对象有没有新意的地方，从而建立研究目标一；② A与C是否有关联，如果有，具有什么样的关联，并且A与C是否可以对B产生影响，这些都是需要明确现状，引出可能的研究思路。在明确上面的研究背景和可能性的推测之后，就是后面的思路整理，细节打磨了。</p><h3 id="研究内容研究目标以及拟解决的关键问题">V.IV.II. 研究内容、研究目标以及拟解决的关键问题</h3><p>项目的研究内容、研究目标，以及拟解决的关键科学问题是申请书应该重点阐述的内容。推荐的撰写模式是先目标后内容的描述，使研究目标、内容、方案、技术路线这一系列内容的撰写符合由简到繁的<strong>逻辑关系</strong>（形成塔形结构）。</p><ul><li>科学问题体现的是内涵，名词表达；</li><li>研究目标体现的是关键问题的解决，动宾结构，是成果体现但不涉及具体工作；</li><li>研究内容体现是的具体的工作，包括实验、测试、分析、模拟、推导等过程的描述，可以有各自的小目标，但是不能体现大的研究目标；</li></ul><p>比如科技园的建设项目立项：</p><ul><li>终极使命：河南理工大学高质量发展中科研能力系统提升模式（名词形式的表达，是所有工作需要解决的背后深层次问题）；</li><li>核心任务：形成特色创新团队；打造优势平台；突破国家人才（科学构架，动宾结构，关键成果）；</li><li>具体工作：成立分析测试中心；建立人才孵化环境；搭建平台培育基地；聚合优势研究力量；引入科研奖惩制度；制定分配资源补给动态（具体工作及过程）。</li></ul><h4 id="研究目标">V.IV.II.I. 研究目标</h4><p>研究目标指这个项目最终要达到的目的（解决的问题）和基本要求，要清晰地显示项目预期成果及其意义，并从逻辑上详细阐明清楚。</p><blockquote><p>针对某一个选定的体系，围绕着什么关键科学问题，用什么方法开展研究，准备理清什么规律，揭示什么机理，解决什么科学问题和学术性问题。</p></blockquote><p>一般研究目标最好为一段精辟的、宏观的用专业术语表达的文字，而不具体分点。对于某些规模较大项目，研究目标也可以分成几点：理论方面要达到什么目的（建立了...）；应用方面要达到的要求（解决了...）；涉及研发类型的方法技术方面要达到的指标等。</p><ul><li>只写研究目标，不用再重复研究意义、研究方法</li><li>研究目标不能过大，也不能“虚”，而要适中（可实现）、简洁明了（实实在在）。体现特色。</li><li>正确处理“抽象”与“实体”内容之间关系。</li><li>同研究内容一致，一项研究内容，必定对应一项研究目标。</li></ul><h4 id="研究内容">V.IV.II.II. 研究内容</h4><p>设计研究内容应当<strong>紧密围绕</strong>项目选题中的科学问题或关键技术问题，组织设计具体、细化的研究框架。不仅写“做什么”，更应该写出“怎么研究”及“具体的研究思路”。</p><ul><li>注意研究内容与研究方案、研究目标的<strong>一致性原则</strong></li><li>不要再重复研究意义，不需要写研究方法，也不用写预期得到什么成果。</li><li>面面俱到，既要避免小题大致，也要避免大题小做。</li><li>针对解决关键的科学问题，把研究内容分为几个组成部分，适当的展开以及详细的描述，表达这个内容的特色及与项目核心内容关联。<ul><li>一个基金面上项目只要求解决一两个科学问题，3～5个方面的内容应该足够了。不等于科研工作的整体规划，避免内容过多。</li><li>把捏好前期研究基础与研究内容的关系</li><li>层层深入，突出重点。建议分层次、分标题、分点罗列，同时注意<strong>逻辑关系</strong><ul><li>不要写成平行的子课题</li><li>是否是解决科学问题的最佳选择，是否足以解决提出的科学问题，是否可行和能否完成，是否具有创新性</li></ul></li></ul></li><li>描述明确、言之有物。对于某些专业词汇，必须要详细的描述。</li><li>研究结果要有力度，不要泛泛的，什么都做。</li></ul><h4 id="拟解决的关键科学问题">V.IV.II.III. 拟解决的关键科学问题</h4><p>拟解决的关键科学问题是项目申请书的核心所在，必然具有一定的深度。对于拟解决的关键问题和技术瓶颈要有清晰的认识，抓准要研究的1～3个关键问题，设想好解决步骤。</p><blockquote><p><a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=575926&amp;do=blog&amp;id=1164670">关键科学问题的内涵是什么呢</a>？在我看来，得满足：（1）若向前推进一步或解决之，有重要意义；（2）属于制约某具体学科领域科学发展的“瓶颈”问题，一旦找到正确的“突破口”或开启“那把锁”的“钥匙”，则势若破竹，能深入揭示隐藏在“黑暗”中的自然现象演化奥秘。虽然自然现象的演化受多种因素影响，但往往“万变不离其宗”，找到了这个“宗”，就等于找到了“突破口”或“钥匙”。</p></blockquote><ul><li>拟解决的关键问题指项目的关键、难点之所在。针对具体对象，阐述为什么难，克服之后其他问题迎刃而解。</li><li>表观的实验现象并不是关键科学问题</li><li>力求写得清楚、准确，反复推敲、仔细提炼，鲜明地亮出来。</li><li>科学问题一般用不太长的一句话表示较好。</li><li>不要与解决的若干具体问题混淆。具体问题一般是由围绕科学问题延伸出来一个或几个组成，且相互之间具有逻辑关系。</li><li>所以需要在随后的研究方案部分给出解决关键问题的方案和对方案思路的可行性分析。</li></ul><h3 id="拟采取的研究方案及可行性分析">V.IV.III. 拟采取的研究方案及可行性分析</h3><h4 id="拟采取的研究方案">V.IV.III.I. 拟采取的研究方案</h4><p>撰写研究方案应围绕研究内容（紧扣研究内容），聚焦关键科学问题（能圆满解答关键科学问题），以清晰的研究思路（指导思想），从研究方法、技术路线、实验手段、关键技术等方面，详述步骤、高招、窍门、可行性等。</p><p>申请人需要对方案的<strong>总体设想和具体细节</strong>两方面都要有所把握。充分体现务实态度和切实可行性。</p><ul><li>洞察到研究的命门所在，并给出方案对策（针对性要强）；</li><li><strong>要体现独一无二的特性</strong>，不能让评议人读起来感觉张三的研究能用，李四的研究也能用，从而失去了研究方案的应有独特价值。</li><li>研究方法、技术路线、实验方案之间逻辑关系明确，一环扣一环。</li><li>具体技术细节的把握则重在高招、窍门和另辟蹊径；</li><li>条理清晰、层次分明、突出主干，图文并茂（淡雅、整洁、大方）。使评审人确信申请人知道该如何开展研究，并且已经准备好开展研究。</li></ul><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20210312130217.png"> <img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20210312130244.png"></p><p><strong>研究方案和研究内容对应</strong>。拟采取的研究方案比研究内容<strong>更加具体</strong>，类似于科研论文的实验部分，但比科研论文的实验部分更加笼统（没那么细），涵盖的工作量也更大。</p><ul><li>拟采用的研究方法是否正确和新颖？</li><li>技术路线是将研究方案细化，与研究方能否保证目标的实现？案密切相关，其实有时两者合在一起。它是具体实施采用的方法步骤细节（分析测试，计统分析，计算模拟等），<ul><li>通常用文字和框图表示，可以很好展示研究路线中的层次关系。</li><li>要注意设计研究路线时步骤的分级和层次之间的逻辑关系，一环扣一环。</li></ul></li><li>实验手段。<ul><li>对于实验过程中所涉及的细节也需要深思熟虑</li></ul></li><li>关键技术属于达到研究目标，完成设定的研究内容时需要使用的若干研究方法技术中相对最为重要的技术，或属于要达到目标的某些“技术瓶颈”。<ul><li>要注意若干个关键技术之间的逻辑关系（主次和重要性），分清楚层次关系。</li></ul></li></ul><h4 id="可行性分析">V.IV.III.II. 可行性分析</h4><p>可行性分析可以从理论可行、方法可行、实验室保障、人员保障主要4个方面介绍。项目的可行性分析要有论点、论据和论证，阐明你的设计方案、研究方法、技术路线能否实现预期的研究目标。</p><p>项目可行性大致由两部分组成：</p><ul><li>项目本身可行性，多从学术思路角度进行论证<ul><li>阐述立项依据是否充分，</li><li>科学问题是否准确可靠可行，</li><li>是否具有相关基础；<ul><li>列举申请人的初步实验结果，则能证明实验方案在实际上是可行的。</li></ul></li><li>通过引用、分析别人或者申请人的文献并结合理论推导，来证明实验思路在理论上是可行的。</li></ul></li><li>实施条件可行性<ul><li>申请人和团队的软硬件条件的可行性，不能过度依赖外部条件。</li><li>研究队伍、研究条件和学术思想方面的综合优势</li></ul></li></ul><h3 id="特色与创新之处">V.IV.IV. 特色与创新之处</h3><p>创新点应在充分查阅文献资料的基础上提出，<font color="red">认真思考、仔细鉴别、深入挖掘</font>课题的区别、特色和创新性，切记不要想当然。</p><p>客观实际的将创新归并到如下几类：理论创新、方法创新、应用创新、集成创新。主要集中于方法的创新、理论的创新和预期结果的创新，主要体现在“选题”和“研究方法路线”两方面，强调“科学性”（学术性）方面的创新或“应用价值”方面的创新性。</p><ul><li>创新点是动宾结构；</li><li>创新点实事求是，否则会失去真实性，或被认为实施困难。</li><li>避免用“填补空白、首次，率先”等词汇，填补国内外空白不是特色与创新。</li><li>不需要洋洋洒洒写一大堆文字，直接把项目的研究特色和创新点说出来。</li><li>如果属于学科交叉项目，必须阐明交叉点在哪儿。</li><li>用词客观。既要体现项目相对目前同行研究的类似项目有点进步，体现“站在前人肩膀上”，但也不能为了抬高自己贬低别人。</li></ul><h3 id="年度研究计划及预期研究结果">V.IV.V. 年度研究计划及预期研究结果</h3><h4 id="年度研究计划">V.IV.V.I. 年度研究计划</h4><p>年度研究计划是指列出在每年度拟开展的实验、数据分析、论文撰写、国际合作和学术交流等工作。</p><ul><li>这要与项目的研究内容和研究方案一致，并且注意不同研究板块的先后顺序和合理分布，不应出现新的工作，也不能遗漏前面已经列出的重要工作。</li><li>要尽量具体一点，要留有余地，便于评审专家了解申请人安排的研究进度是否合理。</li><li>表述需要一目了然，最好能一条一条地罗列。</li><li>在时间的分段方面，不宜太长，也不宜太短。应充分规划每一部分研究内容可能花费的时间，做到合情合理。</li></ul><h4 id="预期研究结果">V.IV.V.II. 预期研究结果</h4><p>预期研究结果通常分成两部分描述：</p><ul><li>预期研究结果则要与研究目标吻合，即针对某关键科学问题，用什么方法开展什么研究，预期能理清什么规律，阐明什么机理，解决什么问题，并预期在本学科主流刊物发表相关的（哪方面的）论文篇数。</li><li>预期研究结果要有力度，有数量，更重质量。</li></ul><h2 id="研究基础与工作条件">V.V. 研究基础与工作条件</h2><h3 id="研究基础">V.V.I. 研究基础</h3><p>研究基础是指与本项目相关的研究工作积累和已取得的研究工作成绩。展示自己在相关研究领域以及在这个课题上的学术积累，指出学术研究思路，证明自己在该领域开展了大量系统研究，发表了系列论文（并且这些论文得到同行的正面引用），在国际学术会议作了邀请报告，有能力做好申请的课题，即要回答“为何我能做”。</p><p>没有研究基础，可以通过这一部分的适当阐述获得基础。比如，我申请方向没有已发表成果，那我就要找在这方面发表成果的学者作为我的参与者。</p><ul><li>不要和立项依据部分介绍申请人前期工作的段落重复，而要根据不同部分的功能和具体的语境调整表述方法和简略程度。</li><li>申请人简历包括申请者和项目组主要成员的学历和研究工作简历，近期已发表与<strong>本项目有关的</strong>主要论著和获得学术奖励情况，及在本项目中承担的任务。<ul><li>要有目的地凝练，不相关的论文可以不提</li></ul></li><li>尤其对于重点基金项目需要认真总结整个团队成员成果基础上，逻辑性地阐明这些基础与本项目之间关系。让评审人看到这个团队成员学科分布较为合理，年龄结构合理，成员学术经历较好，成果有特色，整体处在国内同行中的先进行列。</li></ul><h3 id="工作条件">V.V.II. 工作条件</h3><p>工作条件包括已具备的实验条件，尚缺少的实验条件和拟解决的途径，包括利用国家实验室、国家重点实验室和部门重点实验室等研究基地的计划与落实情况。</p><p>工作条件涉及软硬件条件：</p><ul><li>软件条件涉及申请人团队的学术条件，例如国内外合作条件等。</li><li>硬件条件主要为分析仪器和计算平台两大类。最好能依托相关国家实验室、重点实验室和工程中心研究基地。那样一方面显示项目研究平台优秀，另一方面也表明这些国家平台发挥了作用，是一个双赢表现。<ul><li>需要根据研究方案部分涉及的主要仪器列出个清单，指出哪些仪器是申请人实验室拥有的，哪些是可以在公共研究平台使用的（都需要列出仪器型号），而哪些是准备添置的。这样就会让评审人感到一目了然。</li></ul></li></ul><h3 id="正在承担的与本项目相关的科研项目情况">V.V.III. 正在承担的与本项目相关的科研项目情况</h3><p>正在承担的与本项目相关的科研项目情况是指申请人正在承担的与本项目相关的科研项目情况，包括国家自然科学基金的项目和国家其他科技计划项目，要注明项目的名称和编号、经费来源、起止年月、与本项目的关系及负责的内容等。</p><ul><li>介绍时要注明项目的名称和编号、经费来源、起止年月、与本项目的关系及负责的内容等。这将有助于评审人判断申请人是否有执行项目的经历，并判断申请课题和正在承担课题的相关性。<ul><li>但如果申请人申请的课题和他/她正在承担的课题过于类似，那么评审人有可能会建议申请人先完成他/她正在承担的课题再申请新的课题。</li></ul></li><li>最好能注明获得什么奖励，发表多少论文，引用情况如何，培养了几名研究生，研究生的现状等等。</li></ul><h3 id="完成国家自然科学基金项目情况">V.V.IV. 完成国家自然科学基金项目情况</h3><p>完成国家自然科学基金项目情况是指对申请人负责的前一个已结题科学基金项目（项目名称及批准号）完成情况、后续研究进展及与本申请项目的关系加以详细说明。另附该已结题项目研究工作总结摘要（限500字）和相关成果的详细目录。这将有助于评审人判断申请人负责的前一个已结题科学基金项目是否达到了预期的效果，以此来预测申请人这次如果获得资助，能否取得预期的成绩。</p><p>一方面，研究者应执行好每一个获批的自然科学基金项目，多出成果；另一方面，研究者应撰写好结题报告，包括工作总结摘要。</p><h2 id="经费预算">V.VI. 经费预算</h2><ul><li>认真编撰经费预算。在申请项目时，就要在预算上多花一点时间，做一个真正执行的预算。</li><li>除了常规经费（旅差费，材料费，燃料费，分析测试和计算经费及少量设备费，出版费等），要重视学术交流项目经费的预算（在政策允许前提下留足）。<ul><li>例如团队成员，包括研究生参加国内外学术活动和邀请国际同行访问经费。这些活动对于确保项目产出高水平成果非常重要。</li></ul></li></ul><h1 id="人才计划">VI. 人才计划</h1><p>人才计划分国家的、部委的、地方的等几个级别。国家的嘛，主要是青年千人（小千人）、千人计划（大千人）、百人计划、长江、杰青、优青、新世纪人才等等。地方上还会有一些省市级的杰出青年、学术带头人、某某人才、某某学者。</p><ul><li>青年千人申请40周岁；国家优秀青年基金男38周岁、女40周岁；万人计划青年拔尖人才自然、工程男35周岁女37周岁；青年长江自然、工程38周岁，人文社科45周岁；国家杰出青年基金 45周岁</li></ul><hr><div class="footnotes"><hr><ol><li id="fn1"><p><a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=475824&amp;do=blog&amp;id=1181382">国自然函审结束，抢先了解上会标准</a><a href="#fnref1">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;http://www.nsfc.gov.cn/&quot;&gt;国家自然科学基金&lt;/a&gt;是20世纪80年代初，为推动我国科技体制改革，变革科研经费拨款方式，中国科学院89位院士（学部委员）致函党中央、国务院建议的。自然科学基金坚持支持基础研究，逐渐形成和发展了由研究项目、人才项目和环境条件项目三大系列组成的资助格局。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="科研经验" scheme="http://saili.science/tags/%E7%A7%91%E7%A0%94%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="基金" scheme="http://saili.science/tags/%E5%9F%BA%E9%87%91/"/>
    
  </entry>
  
  <entry>
    <title>在线学习</title>
    <link href="http://saili.science/online-learning/"/>
    <id>http://saili.science/online-learning/</id>
    <published>2018-10-11T12:23:06.000Z</published>
    <updated>2018-10-29T10:15:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习算法可以分成两类。离线学习和在线学习。在线机器学习指每次通过一个训练实例学习模型的学习方法。</p><span id="more"></span><blockquote><p>Gama J, Žliobaitė I, Bifet A, et al. A survey on concept drift adaptation[J]. ACM computing surveys (CSUR), 2014, 46(4): 44.<br>Shalev-Shwartz S. Online learning and online convex optimization[J]. Foundations and Trends® in Machine Learning, 2012, 4(2): 107-194.<br>Žliobaitė I, Pechenizkiy M, Gama J. An overview of concept drift applications[M]//Big data analysis: new algorithms for a new society. Springer, Cham, 2016: 91-114.</p></blockquote><blockquote><p><a href="https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/">A Gentle Introduction to Concept Drift in Machine Learning</a></p></blockquote><p>Concept Drift:</p><h1 id="离线学习与在线学习">I. 离线学习与在线学习</h1><p>We can distinguish two learning modes: offline learning and online learning.</p><h2 id="离线学习">I.I. 离线学习</h2><p>In offline learning the whole training data must be available at the time of model training. Only when training is completed the model can be used for predicting.</p><p>不同理解方式：</p><ul><li>也称批量学习（batch learning）：一个batch训练完才更新权重，这样的话要求所有的数据必须在每一个训练操作中（batch中）都是可用的，这样不会因为偶然的错误把网络带向极端。在监督学习的批量方法中，多层感知器的突出权值的调整在训练样本集合的所有N个例子都出现后进行，这构成了训练的一个回合。换句话说，批量学习的代价函数是由平均误差能量定义的。多层感知器的突触权值的调整是以回合-回合为基础的。相应地，学习曲线的一种实现方式是通过描绘平均误差能量对回合数的图形而得到，对于训练的每一个回合，训练样本集合的样例是随机选取的。学习曲线通过对足够大量的这样实现的总体平均来计算，这里每次实现是在随机选取不同初始条件下完成的。这一特点符合交叉验证的规律，实验中的实验集、验证集、测试集一般都是批量处理的典例。<ul><li>只有训练完成了之后，模型才能被拿来用。简而言之，先训练，再用模型，不训练完就不用模型。</li></ul></li><li>你有一个样本，你把第一条带入训练，调整权重，然后带入下一条，直至跑完整个样本，这个时候的误差率可能不让你满意，于是你把整个样本又做了上述操作，直到误差很小。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">initialize all weights to random value</span><br><span class="line">repeat:</span><br><span class="line">  for t in training_set:</span><br><span class="line">    compute train_error for t</span><br><span class="line">    adjust weights base on train_error</span><br><span class="line">until error rate is very small or error rate variation stops</span><br></pre></td></tr></table></figure></li></ul><p>优点：</p><ol style="list-style-type: decimal"><li>消除样本顺序的影响</li><li>对梯度向量的精确估计，因此，在简单条件下，保证了这一方法最速下降到局部极小点的收敛性。</li><li>学习的并行性。</li></ol><p>缺点：</p><ol style="list-style-type: decimal"><li>有着存储需求</li></ol><h2 id="在线学习">I.II. 在线学习</h2><p>不同理解方式：</p><ul><li>online and batch learning：在线算法按照顺序处理数据，一个数据点训练完了直接更新权重。它们产生一个模型，并在把这个模型放入实际操作中，而不需要在一开始就提供完整的训练数据集。随着更多的实时数据到达，模型会在操作中不断地更新。In contrast, online algorithms process data sequentially. They produce a model and put it in operation without having the complete training data set available at the beginning. The model is continuously updated during operation as more training data arrives. Less restrictive than online algorithms are incremental algorithms that process input examples one by one (or batch by batch) and update the decision model after receiving each example. Incremental algorithms may have random access to previous examples or representative/selected examples. In such a case, these algorithms are called incremental algorithms with partial memory. Typically, in incremental algorithms, for any new presentation of data, the update operation of the model is based on the previous one. Streaming algorithms are online algorithms for processing high-speed continuous flows of data. In streaming, examples are processed sequentially as well and can be examined in only a few passes (typically just one). These algorithms use limited memory and limited processing time per item.<ul><li>通常来讲，一种Online learning算法对于一个序列进行一系列处理可以分为三步<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>：第一步，算法获得一个训练实例；第二步，算法预测训练实例的类别；第三步，算法获得正确类别，并根据预测类别与正确类别更新模型假设。</li><li>我们无法得知这一次的更新权重是正确的还是错误的，如果恰恰是错误的一次更新，那么我们的模型会有可能渐渐地走向错误方向，残差出现。</li></ul></li><li>你有一个样本，你把第一条带入训练，调整权重，再把这一条带进去一次，重复多次，直至误差率很小，然后再带入下一条，直至跑完整个样本。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">initialize all weights to random value</span><br><span class="line">  for t in training_set:</span><br><span class="line">    repeat:</span><br><span class="line">    compute train_error for t</span><br><span class="line">    adjust weights base on train_error</span><br><span class="line">  until error rate is very small or error rate variation stops</span><br></pre></td></tr></table></figure></li></ul><p>在监督学习的在线方法下，对于多层感知器突触权值的调整是以样例-样例为基础的，用来最小化的代价函数是全体瞬时误差能量。和批量学习一样，在线学习的学习曲线是通过足够大量的随机选取的初始条件上的总体平均来计算的。对于给定的网络结构，在线学习下获得的学习曲线和批量学习下获得的学习曲线有着很大的不同。</p><p>给定训练样本以随机的方式呈现给网络，在线学习的使用使得在多维权值空间中的搜索事实上是随机的；正是由于这个原因，在线学习方法有时被称为随机方法。</p><p>优点：</p><ol style="list-style-type: decimal"><li>容易执行</li><li>对于大规模和困难模式分类问题它提供有效解。</li><li>随机性使得不容易陷入局部极值点</li><li>存储量少得多</li></ol><h1 id="增量式算法">II. 增量式算法</h1><p>增量式算法就是每当新增数据时，并不需要重建所有的知识库，而是在原有知识库的基础上，仅做由于新增数据所引起的更新，这更加符合人的思维原理。一个增量学习算法应同时具有以下特点：</p><ul><li>可以从新数据中学习新知识；<br></li><li>以前已经处理过的数据不需要重复处理；</li><li>每次只有一个训练观测样本被看到和学习；</li><li>学习新知识的同时能保存以前学习到的大部分知识；</li><li>—旦学习完成后训练观测样本被丢弃；</li><li>学习系统没有关于整个训练样本的先验知识；</li></ul><h1 id="减量式算法">III. 减量式算法</h1><p>decremental learning，即抛弃“价值最低”的保留的训练样本。这两个概念在incremental and decremental svm这篇论文里面可以看到具体的操作过程。</p><blockquote><p>Cauwenberghs G, Poggio T. Incremental and decremental support vector machine learning[C]//Advances in neural information processing systems. 2001: 409-415.<br>Gâlmeanu H, Andonie R. Implementation issues of an incremental and decremental SVM[C]//International Conference on Artificial Neural Networks. Springer, Berlin, Heidelberg, 2008: 325-335.</p></blockquote><h1 id="实例">IV. 实例</h1><p>两种典型在线机器学习算法：Perceptron、MIRA，他们都属于线性分类算法族，它们具有相同的模型形式。在学习阶段，算法对于每个类别，通过训练数据估计一个参数向量w。在推理阶段，算法在给定一组参数向量w和数据x的条件下，以w和x的乘积作为数据与该类的相似度度量。</p><h2 id="在线学习的二值分类">IV.I. 在线学习的二值分类</h2><blockquote><p><a href="https://qingyuanxingsi.github.io/tag/perception.html">机器学习番外篇之在线学习(I):Online Learning与感知器</a></p></blockquote><p>假设样例按照到来的先后顺序依次定义为<span class="math inline">\(((x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(m)},y^{(m)}))\)</span>。<span class="math inline">\(X\)</span>为样本特征，<span class="math inline">\(y\)</span>为类别标签。我们的任务是到来一个样例<span class="math inline">\(x\)</span>，给出其类别结果<span class="math inline">\(y\)</span>的预测值，之后我们会看到<span class="math inline">\(y\)</span>的真实值，然后根据真实值来重新调整模型参数，整个过程是重复迭代的过程，直到所有的样例完成。</p><p>我们的假设函数为:</p><p><span class="math display">\[\begin{equation} h_{\theta}(x) = g(\theta^T x) \end{equation}\]</span></p><p>其中<span class="math inline">\(x\)</span>是<span class="math inline">\(n+1\)</span>维特征向量,最后一维为常量<span class="math inline">\(1\)</span>，<span class="math inline">\(\theta\)</span>是<span class="math inline">\(n+1\)</span>维参数权重,最后一维表示Bias。函数<span class="math inline">\(g\)</span>用来将<span class="math inline">\(\theta^Tx\)</span>计算结果映射到<span class="math inline">\(-1\)</span>和<span class="math inline">\(1\)</span>上。具体公式如下：</p><p><span class="math display">\[\begin{equation} \begin{split} g(z) = \left \lbrace \begin{array}{cc} 1 &amp; \text{if} \ z \geq 0 \\ -1 &amp; \text{if} \ z &lt; 0 \end{array} \right. \end{split} \end{equation}\]</span></p><p>这个也是logistic回归中<span class="math inline">\(g\)</span>的简化形式。</p><p>现在我们提出一个在线学习算法如下：</p><p>新来一个样例<span class="math inline">\((x,y)\)</span>，我们先用从之前样例学习到的<span class="math inline">\(h_{\theta}(x)\)</span>来得到样例的预测值<span class="math inline">\(y\)</span>，如果<span class="math inline">\(h_{\theta}(x) = y\)</span>（即预测正确），那么不改变<span class="math inline">\(\theta\)</span>，反之</p><p><span class="math display">\[\begin{equation} \theta := \theta + yx \end{equation}\]</span></p><p>也就是说，如果对于预测错误的样例，<span class="math inline">\(\theta\)</span>进行调整时只需加上（实际上为正例）或者减去（实际负例）样本特征<span class="math inline">\(x\)</span>值即可。<span class="math inline">\(\theta\)</span>初始值为向量0。这里我们关心的是<span class="math inline">\(\theta^Tx\)</span>的符号，而不是它的具体值。调整方法非常简单。然而这个简单的调整方法还是很有效的，它的错误率不仅是有上界的，而且这个上界不依赖于样例数和特征维度。</p><p>下面定理阐述了<strong>错误率上界</strong>：</p><blockquote><p>定理（Block and Novikoff）: 给定按照顺序到来的<span class="math inline">\((x^{(1)},y^{(1)}),(x^{(2)},y^{(2)},\cdots,(x^{(m)},y^{(m)}))\)</span>样例。假设对于所有的样例<span class="math inline">\(||x^{(i)} \leq D\)</span>，也就是说特征向量长度有界为<span class="math inline">\(D\)</span>。更进一步，假设存在一个单位长度向量<span class="math inline">\(u\)</span>且<span class="math inline">\(y^{(i)}(u^Tx^{(i)})\geq \gamma\)</span>。也就是说对于<span class="math inline">\(y=1\)</span>的正例，<span class="math inline">\(u^Tx^{(i)} \geq \gamma\)</span>，反例<span class="math inline">\(u^Tx^{(i)} \leq -\gamma\)</span>，<span class="math inline">\(u\)</span>能够有<span class="math inline">\(\gamma\)</span>的间隔将正例和反例分开。那么感知算法的预测的错误样例数不超过<span class="math inline">\(({D \over \gamma})^2\)</span>。</p></blockquote><p>根据对SVM的理解，这个定理就可以阐述为：如果训练样本线性可分，并且几何间距至少是<span class="math inline">\(\gamma\)</span>，样例样本特征向量最长为<span class="math inline">\(D\)</span>，那么感知算法错误数不会超过<span class="math inline">\(({D \over \gamma})^2\)</span>。这个定理是62年提出的，63年Vapnik提出SVM，可见提出也不是偶然的，感知算法也许是当时的热门。</p><div class="note info"><p>定理证明</p></div><p>感知算法只在样例预测错误时进行更新，定义<span class="math inline">\(\theta^{(k)}\)</span>是第<span class="math inline">\(k\)</span>次预测错误时使用的样本特征权重，<span class="math inline">\(\theta^{(1)} = \vec{0}\)</span> 初始化为<span class="math inline">\(\vec{0}\)</span>向量。假设第<span class="math inline">\(k\)</span>次预测错误发生在样例<span class="math inline">\((x^{(i)},y^{(i)})\)</span>上，利用<span class="math inline">\(\theta^{(k)}\)</span>计算<span class="math inline">\(y^{(i)}\)</span>值时得到的结果不正确。也就是说下面的公式成立：</p><p><span class="math display">\[\begin{equation} (x^{(i)})^T\theta^{(k)}y^{(i)} \leq 0 \end{equation}\]</span></p><p>根据感知算法的更新方法，我们有<span class="math inline">\(\theta^{(k+1)} = \theta^{(k)} + y^{(i)}x^{(i)}\)</span>。这时候，两边都乘以<span class="math inline">\(u\)</span>得到:</p><p><span class="math display">\[\begin{equation} \begin{split} (\theta^{(k+1)})^Tu &amp;= (\theta^{(k)})^u + y^{(i)}(x^{(i)})^Tu \\ &amp;\geq (\theta^{(k)})^Tu + \gamma \end{split} \end{equation}\]</span></p><p>这个式子是个递推公式，就像等差数列一样<span class="math inline">\(f_{n+1}=f_n+d\)</span>。由此我们可得</p><p><span class="math display">\[\begin{equation} (\theta^{(k+1)})^Tu \geq k\gamma \end{equation}\]</span></p><p>因为初始<span class="math inline">\(\theta\)</span>为<span class="math inline">\(\vec{0}\)</span>。</p><p>下面我们利用前面推导出的<span class="math inline">\((x^{(i)})^T\theta^{(k)}y^{(i)} \leq 0\)</span>和<span class="math inline">\(||x^{(i)}|| \leq D\)</span>得到</p><p><span class="math display">\[\begin{equation} \begin{split} ||\theta^{(k+1)}||^2 &amp;= ||\theta^{(k)} + y^{(i)}x^{(i)}||^2 \\ &amp;= ||\theta^{k}||^2 + ||x^{(i)}||^2 + 2y^{(i)}(x^{(i)})^T\theta^{(i)} \\ &amp;\leq ||\theta^{k}||^2 + ||x^{(i)}||^2 \\ &amp;\leq ||\theta^{k}||^2 + D^2 \end{split} \end{equation}\]</span></p><p>也就是说<span class="math inline">\(\theta^{(k+1)}\)</span>的长度平方不会超过<span class="math inline">\(\theta^{(k)}\)</span>与<span class="math inline">\(D\)</span>的平方和。</p><p>又是一个等差不等式，得到：</p><p><span class="math display">\[\begin{equation} ||\theta^{k+1}||^2 \leq kD^2 \end{equation}\]</span></p><p>两边开根号得：</p><p><span class="math display">\[\begin{equation} \begin{split} \sqrt{k}D &amp; \geq ||\theta^{(k+1)}|| \\ &amp; \geq (\theta^{(k+1)})^Tu \\ &amp; \geq k\gamma \end{split} \end{equation}\]</span></p><p>其中第二步可能有点迷惑，我们细想<span class="math inline">\(u\)</span>是单位向量的话:</p><p><span class="math display">\[\begin{equation} z^Tu = ||z||||u||cos \phi \leq ||z||||u|| \end{equation}\]</span></p><p>因此上面的不等式成立，最后得到：</p><p><span class="math display">\[\begin{equation} k \leq (D/\gamma)^2 \end{equation}\]</span></p><p>也就是预测错误的数目不会超过样本特征向量<span class="math inline">\(x\)</span>的最长长度除以几何间隔的平方。实际上整个调整过程中<span class="math inline">\(\theta\)</span>就是<span class="math inline">\(x\)</span>的线性组合。</p><h1 id="代码资源">V. 代码资源</h1><ul><li><a href="https://www.cs.huji.ac.il/~shais/">Shai Shalev-Shwartz</a></li></ul><div class="footnotes"><hr><ol><li id="fn1"><p><a href="http://yjliu.net/blog/2012/07/14/a-brief-talk-about-online-learning.html">浅谈在线机器学习算法</a><a href="#fnref1">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器学习算法可以分成两类。离线学习和在线学习。在线机器学习指每次通过一个训练实例学习模型的学习方法。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
    <category term="OnlineLearning" scheme="http://saili.science/tags/OnlineLearning/"/>
    
  </entry>
  
  <entry>
    <title>协方差矩阵</title>
    <link href="http://saili.science/covariance/"/>
    <id>http://saili.science/covariance/</id>
    <published>2018-07-19T13:39:13.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>在统计学与概率论中，协方差矩阵（也称离差矩阵、方差-协方差矩阵）是一个矩阵，其 i, j 位置的元素是第 i 个与第 j 个随机向量（即随机变量构成的向量）之间的协方差。这是从标量随机变量到高维度随机向量的自然推广。</p><span id="more"></span><p>首先定义一个含有n个样本的集合<span class="math inline">\(X=\{X_1,\ldots,X_n\}\)</span>，</p><ul><li>均值：<span class="math inline">\(\bar{X}=\frac{\sum_{i=1}^n X_{i}}{n}\)</span></li><li>标准差：<span class="math inline">\(s=\sqrt{\frac{\sum_{i=1}^n (X_{i}-\bar{X})^2}{n-1}}\)</span></li><li>方差：<span class="math inline">\(s^2=\frac{\sum_{i=1}^n (X_{i}-\bar{X})^2}{n-1}\)</span></li></ul><p>均值描述的是样本集合的中间点，它告诉我们的信息是很有限的，而标准差给我们描述的则是样本集合的各个样本点到均值的距离之平均。标准差描述的就是这种“散布度”。之所以除以<span class="math inline">\(n-1\)</span>而不是除以<span class="math inline">\(n\)</span>，是因为这样能使我们以较小的样本集更好的逼近总体的标准差，即统计上所谓的“无偏估计”。</p><p>但我们应该注意到，标准差和方差一般是用来描述一维数据的，但现实生活我们常常遇到含有多维数据的数据集。协方差就是这样一种用来度量两个随机变量关系的统计量，我们可以仿照方差的定义：</p><p><span class="math display">\[var(X)=\frac{\sum_{i=1}^n (X_{i}-\bar{X})(X_{i}-\bar{X})}{n-1}\]</span></p><p>来度量各个维度偏离其均值的程度，标准差可以这么来定义：</p><p><span class="math display">\[cov(X,Y)=cov(Y,X)=var(X)=\frac{\sum_{i=1}^n (X_{i}-\bar{X})(Y_{i}-\bar{Y})}{n-1}\]</span></p><p>如果结果为正值，则说明两者是正相关的(从协方差可以引出“相关系数”的定义)。如果为0，也是就是统计上说的“相互独立”。</p><p>协方差也只能处理二维问题，那维数多了自然就需要计算多个协方差，比如<span class="math inline">\(n\)</span>维的数据集就需要计算<span class="math inline">\(\frac{n!}{(n-2)!* 2}\)</span>个协方差，那自然而然的我们会想到使用矩阵来组织这些数据。给出协方差矩阵的定义：</p><p><span class="math display">\[C_{n\times n}=(c_{i,j},c_{i,j}=cov(Dim_{i},Dim_{j}))\]</span></p><p>假设数据集有<span class="math inline">\(\{x,y,z\}\)</span>三个维度，则协方差矩阵为</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20190418135351.png"></p><p>可见，协方差矩阵是一个对称的矩阵，而且对角线是各个维度上的方差。协方差矩阵计算的是不同维度之间的协方差，而不是不同样本之间的。</p><h1 id="matlab-实现">I. MATLAB 实现</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">% 方法一</span><br><span class="line">MySample = fix(rand(10,3)*50)</span><br><span class="line">dim1 = MySample(:,1);</span><br><span class="line">dim2 = MySample(:,2);</span><br><span class="line">dim3 = MySample(:,3);</span><br><span class="line">sum( (dim1-mean(dim1)) .* (dim2-mean(dim2)) ) / ( size(MySample,1)-1 )</span><br><span class="line">% 得到  74.5333</span><br><span class="line">sum( (dim1-mean(dim1)) .* (dim3-mean(dim3)) ) / ( size(MySample,1)-1 )</span><br><span class="line">% 得到  -10.0889</span><br><span class="line">sum( (dim2-mean(dim2)) .* (dim3-mean(dim3)) ) / ( size(MySample,1)-1 )</span><br><span class="line">% 得到  -106.4000</span><br><span class="line">std(dim1)^2 % 得到   108.3222</span><br><span class="line">std(dim2)^2 % 得到   260.6222</span><br><span class="line">std(dim3)^2 % 得到   94.1778</span><br><span class="line"></span><br><span class="line">% 方法二</span><br><span class="line">% 先让样本矩阵中心化，即每一维度减去该维度的均值，使每一维度上的均值为0</span><br><span class="line">% 然后直接用新的到的样本矩阵乘上它的转置，然后除以(N-1)即可。</span><br><span class="line">X = MySample - repmat(mean(MySample),10,1);</span><br><span class="line">% 中心化样本矩阵，使各维度均值为0</span><br><span class="line">C = (X&#x27;*X)./(size(X,1)-1);</span><br><span class="line"></span><br><span class="line">% 方法三</span><br><span class="line">cov(MySample)</span><br></pre></td></tr></table></figure><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在统计学与概率论中，协方差矩阵（也称离差矩阵、方差-协方差矩阵）是一个矩阵，其 i, j 位置的元素是第 i 个与第 j 个随机向量（即随机变量构成的向量）之间的协方差。这是从标量随机变量到高维度随机向量的自然推广。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="CovarianceMatrix" scheme="http://saili.science/tags/CovarianceMatrix/"/>
    
  </entry>
  
  <entry>
    <title>数据处理</title>
    <link href="http://saili.science/data-process/"/>
    <id>http://saili.science/data-process/</id>
    <published>2018-07-14T13:24:58.000Z</published>
    <updated>2018-08-13T07:03:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>如果把重点放在数据的处理方式上，那么长期共存的方式大概有两种：</p><ul><li>特征学习(feature learning)，又叫表示学习(representation learning)或者表征学习 。特征学习是从数据中自动抽取特征或者表示的方法，这个学习过程是模型自主的。</li><li>特征工程(feature engineering)，主要指对于数据的人为处理提取，有时候也代指“洗数据” 。特征工程的过程是人为的对数据进行处理，得到我们认为的、适合后续模型使用的样式。</li></ul><span id="more"></span><p>综上，机器学习模型对于数据的处理可以被大致归类到两个方向<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>：</p><ul><li>表示学习：模型自动对输入数据进行学习，得到更有利于使用的特征(可能同时做出了预测)。代表的算法大致包括： 深度学习，包括大部分常见的模型如cnn/rnn/dbn，也包括迁移学习等某些无监督学习算法，如主成分分析(PCA)通过对数据转化而使得输入数据更有意义，某些树模型可以自动的学习到数据中的特征并同时作出预测。</li><li>特征工程：模型依赖人为处理的数据特征，而模型的主要任务是预测，比如简单的线性回归期待良好的输入数据(如离散化后的数据) 。</li></ul><p>这个不是一个严谨的科学划分，是一种直观的理解。如果所使用的模型拥有对于数据的简化、特征表示和抽取能力，我们都可以认为它是有表示学习的特性。狭义的特征工程指的是处理缺失值、特征选择、维度压缩等各种预处理手段，而从更大的角度看主要目的是提高数据的表示能力。对于数据的人为提炼使其有了更好的表达，这其实是人工的表示学习。</p><p>传统的机器学习方法主要依赖人工特征处理与提取，而深度学习依赖模型自身去学习数据的表示。</p><p>深度学习的层层网络可以从数据中自动学习到有用的、高度抽象的特征，而最终目的是为了帮助分类层做出良好的预测。深度学习的一大特点是其对数据的分布式表示(distributed representation)(也和稀疏性表示等其他特性有关)，最直观的例子可以是<code>nlp</code>中的<code>word2vec</code>，每个单词不再是割裂的而互相有了关联。类似的，不少网络中的参数共享就是分布式表示，不仅降低了参数量需求也提高对于数据的描述能力。仅看分类层的话，深度学习和其他的机器学习似乎没有天壤之别，但正因为有了种种良好的表示学习能力使其有了过人之处。</p><p>在数据量不够的时候，自动特征抽取的方法往往不如人为的特征工程。当使用者对于数据和问题有深刻的理解时，人工的特征工程往往效果更好。同时也值得注意，表示学习的另一好处是高度抽象化的特征往往可以被应用于相关的领域上，这也是我们常说的迁移学习(transfer learning)的思路。比如有了大量猫的图片以后，不仅可以用于预测一个物体是不是猫，也可以用于将抽取到的特征再运用于其他类似的领域从而节省数据开销。</p><p>从某个角度来看，表示学习有“嵌入式的特征选择”(embedded feature selection)的特性，其表示学习嵌入到了模型中。举个简单的例子，决策树模型在训练过程中可以同时学习到不同特征的重要性，而这个过程是建模的一部分，是一种嵌入式的特征选择。</p><p>首先对于模型选择有一定的帮助：当我们数据量不大，且对于数据非常理解时，人为的特征处理也就是特征工程是合适的。比如去掉无关数据、选择适合的数据、合并数据、对数据做离散化等。 当数据量较大或者我们的人为先验理解很有限时，可以尝试表示学习，如依赖一气呵成的深度学习，效果往往不错。</p><div class="footnotes"><hr><ol><li id="fn1"><p><a href="https://mp.weixin.qq.com/s/iChtcYb7M-KQiMeiE6EYwA">人工智能是如何处理数据的？</a><a href="#fnref1">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;如果把重点放在数据的处理方式上，那么长期共存的方式大概有两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特征学习(feature learning)，又叫表示学习(representation learning)或者表征学习 。特征学习是从数据中自动抽取特征或者表示的方法，这个学习过程是模型自主的。&lt;/li&gt;
&lt;li&gt;特征工程(feature engineering)，主要指对于数据的人为处理提取，有时候也代指“洗数据” 。特征工程的过程是人为的对数据进行处理，得到我们认为的、适合后续模型使用的样式。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="Feature" scheme="http://saili.science/tags/Feature/"/>
    
  </entry>
  
  <entry>
    <title>卡尔曼滤波</title>
    <link href="http://saili.science/kalman-filter/"/>
    <id>http://saili.science/kalman-filter/</id>
    <published>2018-07-12T06:29:06.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>卡尔曼滤波（Kalman filtering）一种利用线性系统状态方程，通过系统输入输出观测数据，对系统状态进行最优估计的算法。由于观测数据中包括系统中的噪声和干扰的影响，所以最优估计也可看作是滤波过程。 <span id="more"></span></p><h1 id="卡尔曼滤波器">I. 卡尔曼滤波器</h1><h1 id="扩展卡尔曼滤波器">II. 扩展卡尔曼滤波器</h1><p>经典的卡尔曼滤波只适用于线性且满足高斯分布的系统，但实际工程中并不是这么简单，比如飞行器在水平运动时有可能伴随着自身的自旋，此时的系统并不是线性的，这时就需要应用扩展卡尔曼滤波（EKF）来解决这种情况<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>。</p><p>在扩展卡尔曼滤波器（Extended Kalman Filter，简称EKF）中状态转换和观测模型不需要是状态的线性函数，可替换为（可微的）函数。函数f可以用来从过去的估计值中计算预测的状态，相似的，函数h可以用来以预测的状态计算预测的测量值。然而f和h不能直接的应用在协方差中，取而代之的是计算偏导矩阵（<a href="https://zh.wikipedia.org/wiki/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5" title="雅可比矩阵">Jacobian</a>）。</p><p><span class="math display">\[{  {x} }_{k}=f({  {x} }_{k-1},{  {u} }_{k},{  {w} }_{k})\]</span></p><p>当前状态的概率分布是关于上一状态和将要执行的控制量的二元函数，再叠加一个高斯噪声，测量值同样是关于当前状态的函数叠加高斯噪声。具体表达式如下： <span class="math inline">\(g(u_t, x_{t-1})\)</span> 和 <span class="math inline">\(h(x_t)\)</span> 可以是非线性的函数。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65ly1ft727nc1q5j305y01pmwz.jpg"></p><p>为了用经典卡尔曼滤波器的思想来解决非线性系统中的状态估计问题，首先要做的就是把 <span class="math inline">\(g(u_t, x_{t-1})\)</span> 和 <span class="math inline">\(h(x_t)\)</span> 用泰勒级数展开，将其线性化，只取一次项为一阶EKF滤波。具体如下：</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65ly1ft727zhqp4j30ds02kjrb.jpg"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65ly1ft7284zz0dj309f02sdfq.jpg"></p><p><span class="math inline">\(g(u_t, x_{t-1})\)</span> 在上一状态估计的最优值处取一阶导数，<span class="math inline">\(h(x_t)\)</span> 在当前时刻预测值处取一阶导数，得到G和H分别相当于Kalman Filter中的A和C。</p><p>在每一步中使用当前的估计状态计算Jacobian矩阵，这几个矩阵可以用在卡尔曼滤波器的方程中。这个过程，实质上将非线性的函数在当前估计值处线性化了。</p><p>这样一来，卡尔曼滤波器的等式为（非线性离散方程，对于非线性连续微分方程来说，需要先一阶近似离散）：</p><p><span class="math display">\[{\hat {  {x} } }_{k|k-1}=f({  {x} }_{k-1},{  {u} }_{k},0)\]</span></p><p>使用<a href="https://sli1989.github.io/jacobian/">Jacobians矩阵</a>更新模型：</p><p><span class="math display">\[ {F}_{k}=\left.{\frac {\partial f}{\partial {  {x} } } }\right\vert _{ {\hat {x} }_{k-1|k-1},{ {u} }_{k} } \]</span></p><p><span class="math display">\[ {  {H} }_{k}=\left.{\frac {\partial h}{\partial {  {x} } } }\right\vert _{ {\hat{x} }_{k|k-1} } \]</span></p><p>状态矩阵A的雅克比矩阵：</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65ly1ft728pukycj30dc05jdgc.jpg"></p><p>观测矩阵H的雅克比矩阵：</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65ly1ft728yklm7j30dc06xaax.jpg"></p><p><strong>Extended Kalman Filter五条黄金公式</strong> ：</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65ly1ft7296560fj30fa04owet.jpg"></p><h2 id="更新">II.I. 更新</h2><p><span class="math display">\[{\displaystyle {\tilde {  {y} } }_{k}={  {z} }_{k}-h({\hat {  {x} } }_{k|k-1},0)}\]</span></p><p><span class="math display">\[{\displaystyle {  {S} }_{k}={  {H} }_{k}{  {P} }_{k|k-1}{  {H} }_{k}^{T}+{  {R} }_{k} }\]</span></p><p><span class="math display">\[{\displaystyle {  {K} }_{k}={  {P} }_{k|k-1}{  {H} }_{k}^{T}{  {S} }_{k}^{-1} }\]</span></p><p><span class="math display">\[{\displaystyle {\hat {  {x} } }_{k|k}={\hat {  {x} } }_{k|k-1}+{  {K} }_{k}{\tilde {  {y} } }_{k} }\]</span></p><p><span class="math display">\[{\displaystyle {  {P} }_{k|k}=(I-{  {K} }_{k}{  {H} }_{k}){  {P} }_{k|k-1} }\]</span></p><h2 id="预测">II.II. 预测</h2><p>如同扩展卡尔曼滤波器（EKF）一样， UKF的预测过程可以独立于UKF的更新过程之外，与一个线性的（或者确实是扩展卡尔曼滤波器的）更新过程合并来使用；或者，UKF的预测过程与更新过程在上述中地位互换亦可。</p><h2 id="matlab实现">II.III. MATLAB实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">% author :  Perry.Li  @USTC</span><br><span class="line">% function: simulating the process of EKF</span><br><span class="line">% date:     04/28/2015</span><br><span class="line">%</span><br><span class="line">N = 50;         %计算连续N个时刻</span><br><span class="line">n=3;            %状态维度</span><br><span class="line">q=0.1;          %过程标准差</span><br><span class="line">r=0.2;          %测量标准差</span><br><span class="line">Q=q^2*eye(n);   %过程方差</span><br><span class="line">R=r^2;          %测量值的方差</span><br><span class="line">% 离散状态方程</span><br><span class="line">f=@(x)[x(2);x(3);0.05*x(1)*(x(2)+x(3))];  %状态方程</span><br><span class="line">h=@(x)[x(1);x(2);x(3)];                   %测量方程</span><br><span class="line">s=[0;0;1];                                %初始状态</span><br><span class="line">%初始化状态</span><br><span class="line">x=s+q*randn(3,1);                         </span><br><span class="line">P = eye(n);                               </span><br><span class="line">xV = zeros(n,N);          </span><br><span class="line">sV = zeros(n,N);         </span><br><span class="line">zV = zeros(n,N);</span><br><span class="line">for k=1:N</span><br><span class="line">  z = h(s) + r*randn;                     </span><br><span class="line">  sV(:,k)= s;                             %实际状态</span><br><span class="line">  zV(:,k)  = z;                           %状态测量值</span><br><span class="line">  [x1,A]=jaccsd(f,x); %计算f的雅可比矩阵，其中x1对应黄金公式line2</span><br><span class="line">  P=A*P*A&#x27;+Q;         %过程方差预测，对应line3</span><br><span class="line">  [z1,H]=jaccsd(h,x1); %计算h的雅可比矩阵</span><br><span class="line">  K=P*H&#x27;*inv(H*P*H&#x27;+R); %卡尔曼增益，对应line4</span><br><span class="line">  x=x1+K*(z-z1);        %状态EKF估计值，对应line5</span><br><span class="line">  P=P-K*H*P;            %EKF方差，对应line6</span><br><span class="line">  xV(:,k) = x;          %save</span><br><span class="line">  s = f(s) + q*randn(3,1);  %update process</span><br><span class="line">end</span><br><span class="line">for k=1:3</span><br><span class="line">  FontSize=14;</span><br><span class="line">  LineWidth=1;</span><br><span class="line">  figure();</span><br><span class="line">  plot(sV(k,:),&#x27;g-&#x27;); %画出真实值</span><br><span class="line">  hold on;</span><br><span class="line">  plot(xV(k,:),&#x27;b-&#x27;,&#x27;LineWidth&#x27;,LineWidth) %画出最优估计值</span><br><span class="line">  hold on;</span><br><span class="line">  plot(zV(k,:),&#x27;k+&#x27;); %画出状态测量值</span><br><span class="line">  hold on;</span><br><span class="line">  legend(&#x27;真实状态&#x27;, &#x27;EKF最优估计估计值&#x27;,&#x27;状态测量值&#x27;);</span><br><span class="line">  xl=xlabel(&#x27;时间(分钟)&#x27;);</span><br><span class="line">  t=[&#x27;状态 &#x27;,num2str(k)] ;</span><br><span class="line">  yl=ylabel(t);</span><br><span class="line">  set(xl,&#x27;fontsize&#x27;,FontSize);</span><br><span class="line">  set(yl,&#x27;fontsize&#x27;,FontSize);</span><br><span class="line">  hold off;</span><br><span class="line">  set(gca,&#x27;FontSize&#x27;,FontSize);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">function [z,A]=jaccsd(fun,x)</span><br><span class="line">% JACCSD Jacobian through complex step differentiation</span><br><span class="line">% [z J] = jaccsd(f,x)</span><br><span class="line">% z = f(x)</span><br><span class="line">% J = f&#x27;(x)</span><br><span class="line">%</span><br><span class="line">z=fun(x);</span><br><span class="line">n=numel(x);</span><br><span class="line">m=numel(z);</span><br><span class="line">A=zeros(m,n);</span><br><span class="line">h=n*eps;</span><br><span class="line">for k=1:n</span><br><span class="line">    x1=x;</span><br><span class="line">    x1(k)=x1(k)+h*i;</span><br><span class="line">    A(:,k)=imag(fun(x1))/h;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><div class="footnotes"><hr><ol><li id="fn1"><p><a href="http://blog.csdn.net/lizilpl/article/details/45289541">扩展卡尔曼滤波器的原理及应用</a><a href="#fnref1">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;卡尔曼滤波（Kalman filtering）一种利用线性系统状态方程，通过系统输入输出观测数据，对系统状态进行最优估计的算法。由于观测数据中包括系统中的噪声和干扰的影响，所以最优估计也可看作是滤波过程。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="StateEstimation" scheme="http://saili.science/tags/StateEstimation/"/>
    
  </entry>
  
  <entry>
    <title>损失函数</title>
    <link href="http://saili.science/cost-function/"/>
    <id>http://saili.science/cost-function/</id>
    <published>2018-06-24T08:12:27.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习中所有的算法都需要最大化或最小化一个函数，这个函数被称为“目标函数”。其中，我们一般把最小化的一类函数，称为“损失函数”。损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数，通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。在一些优化函数的辅助下，损失函数逐渐学会减少预测值的误差。损失函数是机器学习优化中至关重要的一部分，是一种评估特定算法对给定数据建模程度的方法，是经验风险函数的核心部分，也是结构风险函数重要组成部分。</p><span id="more"></span><p>模型的结构风险函数包括了经验风险项和正则项，如式<span class="math inline">\(\eqref{Structural-risk-function}\)</span>所示。其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的<span class="math inline">\(\Phi\)</span>是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ值。</p><p><span class="math display">\[\begin{equation}\theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Phi(\theta)\end{equation}\label{Structural-risk-function}\]</span></p><p>损失函数大致可分为两类：分类问题的损失函数和回归问题的损失函数<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>。在实际应用中，选取损失函数会受到诸多因素的制约，比如是否有异常值、机器学习算法的选择、梯度下降的时间复杂度、求导的难易程度以及预测值的置信度等等。因此，不存在一种损失函数适用于处理所有类型的数据。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20190418134747.png"></p><h1 id="回归问题">I. 回归问题</h1><p>均方误差(MSE)是最常用的回归损失函数，计算方法是求预测值与真实值之间距离的平方和。它只考虑误差的平均大小，不考虑其方向。但由于经过平方，与真实值偏离较多的预测值会比偏离较少的预测值受到更为严重的惩罚。再加上 MSE 的数学特性很好，这使得计算梯度变得更容易。</p><p>平均绝对误差（MAE，也称L1损失）是另一种用于回归模型的损失函数。MAE是目标值和预测值之差的绝对值之和。其只衡量了预测值误差的平均模长，而不考虑方向，取值范围也是从0到正无穷（如果考虑方向，则是残差/误差的总和——平均偏差（MBE））。</p><ul><li>和 MSE 一样，这种度量方法也是在不考虑方向的情况下衡量误差大小。但和 MSE 的不同之处在于，MAE 需要像线性规划这样更复杂的工具来计算梯度。</li><li>简单来说，MSE计算简便，但MAE对异常点有更好的鲁棒性（更加稳健）。MSE对误差取了平方（令e=真实值-预测值），因此若e&gt;1，则MSE会进一步增大误差。如果数据中存在异常点，那么e值就会很大，而e²则会远大于|e|。因此，相对于使用MAE计算损失，使用MSE的模型会赋予异常点更大的权重。用RMSE计算损失的模型会以牺牲了其他样本的误差为代价，朝着减小异常点误差的方向更新。然而这就会降低模型的整体性能。如果训练数据被异常点所污染，那么MAE损失就更好用（比如，在训练数据中存在大量错误的反例和正例标记，但是在测试集中没有这个问题）。</li><li>直观上可以这样理解：如果我们最小化MSE来对所有的样本点只给出一个预测值，那么这个值一定是所有目标值的平均值。但如果是最小化MAE，那么这个值，则会是所有样本点目标值的中位数。众所周知，对异常值而言，中位数比均值更加鲁棒，因此MAE对于异常值也比MSE更稳定。</li><li>然而MAE存在一个严重的问题（特别是对于神经网络）：更新的梯度始终相同，也就是说，即使对于很小的损失值，梯度也很大。这样不利于模型的学习。为了解决这个缺陷，我们可以使用变化的学习率，在损失接近最小值时降低学习率。而MSE在这种情况下的表现就很好，即便使用固定的学习率也可以有效收敛。MSE损失的梯度随损失增大而增大，而损失趋于0时则会减小。这使得在训练结束时，使用MSE模型的结果会更精确。推荐大家读一下<a href="http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/">这篇文章</a>，文中比较了分别使用L1、L2损失的回归模型在有无异常值时的表现。总而言之，处理异常点时，L1损失函数更稳定，但它的导数不连续，因此求解效率较低。L2损失函数对异常点更敏感，但通过令其导数为0，可以得到更稳定的封闭解。</li></ul><p>平均偏差误差（mean bias error）：与其它损失函数相比，这个函数在机器学习领域没有那么常见。它与 MAE 相似，唯一的区别是这个函数没有用绝对值。用这个函数需要注意的一点是，正负误差可以互相抵消。尽管在实际应用中没那么准确，但它可以确定模型存在正偏差还是负偏差。</p><p>Huber损失，平滑的平均绝对误差。Huber损失对数据中的异常点没有平方误差损失那么敏感。它在0也可微分。本质上，Huber损失是绝对误差，只是在误差很小时，就变为平方误差。误差降到多小时变为二次误差由超参数δ（delta）来控制。当Huber损失在[0-δ,0+δ]之间时，等价为MSE，而在[-∞,δ]和[δ,+∞]时为MAE。</p><ul><li>使用MAE训练神经网络最大的一个问题就是不变的大梯度，这可能导致在使用梯度下降快要结束时，错过了最小点。而对于MSE，梯度会随着损失的减小而减小，使结果更加精确。在这种情况下，Huber损失就非常有用。它会由于梯度的减小而落在最小值附近。比起MSE，它对异常点更加鲁棒。因此，Huber损失结合了MSE和MAE的优点。但是，Huber损失的问题是我们可能需要不断调整超参数delta。</li></ul><p>Log-cosh是另一种应用于回归问题中的，且比L2更平滑的的损失函数。它的计算方式是预测误差的双曲余弦的对数。优点：对于较小的x，log(cosh(x))近似等于(x^2)/2，对于较大的x，近似等于abs(x)-log(2)。这意味着‘logcosh’基本类似于均方误差，但不易受到异常点的影响。它具有Huber损失所有的优点，但不同于Huber损失的是，Log-cosh二阶处处可微。但Log-cosh损失也并非完美，其仍存在某些问题。比如误差很大的话，一阶梯度和Hessian会变成定值，这就导致XGBoost出现缺少分裂点的情况。(许多机器学习模型如XGBoost，就是采用牛顿法来寻找最优点。而牛顿法就需要求解二阶导数（Hessian）。因此对于诸如XGBoost这类机器学习框架，损失函数的二阶可微是很有必要的。)</p><p>当我们更关注区间预测而不仅是点预测时，分位数损失函数就很有用。使用最小二乘回归进行区间预测，基于的假设是残差（y-y_hat）是独立变量，且方差保持不变。如何选取合适的分位值取决于我们对正误差和反误差的重视程度。损失函数通过分位值（γ）对高估和低估给予不同的惩罚。</p><p>仿真对比的一些观察结果<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>：</p><ul><li>MAE损失模型的预测结果受脉冲噪声的影响较小，而MSE损失函数的预测结果受此影响略有偏移。</li><li>Huber损失模型预测结果对所选超参数不敏感。</li><li>分位数损失模型在合适的置信水平下能给出很好的估计。</li></ul><h1 id="分类问题">II. 分类问题</h1><p>Hinge Loss/多分类 SVM 损失：简言之，在一定的安全间隔内（通常是 1），正确类别的分数应高于所有错误类别的分数之和。因此 hinge loss 常用于最大间隔分类（maximum-margin classification），最常用的是支持向量机。尽管不可微，但它是一个凸函数，因此可以轻而易举地使用机器学习领域中常用的凸优化器。</p><p>交叉熵损失/负对数似然：这是分类问题中最常见的设置。随着预测概率偏离实际标签，交叉熵损失会逐渐增加。</p><div class="footnotes"><hr><ol><li id="fn1"><p><a href="http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/">机器学习-损失函数</a><a href="#fnref1">↩</a></p></li><li id="fn2"><p><a href="https://www.jiqizhixin.com/articles/2018-06-21-3">机器学习大牛最常用的5个回归损失函数，你知道几个？</a><a href="#fnref2">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器学习中所有的算法都需要最大化或最小化一个函数，这个函数被称为“目标函数”。其中，我们一般把最小化的一类函数，称为“损失函数”。损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数，通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。在一些优化函数的辅助下，损失函数逐渐学会减少预测值的误差。损失函数是机器学习优化中至关重要的一部分，是一种评估特定算法对给定数据建模程度的方法，是经验风险函数的核心部分，也是结构风险函数重要组成部分。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>模型选择</title>
    <link href="http://saili.science/model-selection/"/>
    <id>http://saili.science/model-selection/</id>
    <published>2018-05-23T12:33:57.000Z</published>
    <updated>2018-05-23T12:58:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>在机器学习中，有一种叫做“没有免费的午餐”的定理，即没有任何一种ML算法在处理所有问题的时候都适合。不同ML算法的性能很大程度上取决于数据的大小和结构。模型的预测能力通常也被称作模型的泛化能力，表示模型在新的、独立的测试数据上的预测能力。</p><span id="more"></span><p>可能不少人觉得此处获取较好模型是指模型评价，但是模型评价与模型选择是两个不同的概念，代表两个不同的阶段：</p><ul><li><strong>模型选择</strong>：根据一组不同复杂度的模型表现，即从某个模型空间中挑选最好的模型；</li><li><strong>模型评价</strong>：选择一个（最好）模型后，在新的数据上来评价其预测误差等评价指标。</li></ul><p>从定义看，两者的目标不同，模型评价是模型选择的后一步。换句话说，模型选择是在某个模型类中选择最好的模型，而模型评价对这个最好的模型进行评价。</p><p>模型评价可以比较多个模型类中的最佳模型，然后从中挑选出最佳模型，亦或者进行模型融合再进行评价。</p><p>随着机器学习普及，大家都有了 “训练 - 验证 - 评价” 的思维，这其实就是完整重现模型选择、模型评价的过程。如下图我们将数据集分成三个不相交的集合来做模型选择和模型评价：</p><ul><li>训练集：获得模型及其训练误差，用来训练不同模型；</li><li>验证集：与训练集相对独立，获取训练模型在该集上的预测误差，用来做模型选择；</li><li>测试集：与训练集和验证集独立，获得真实的测试误差和其他模型评价指标，用来评价已选择出的模型。</li></ul><p>使用训练集、验证集目的就是做模型选择，测试集自然是做模型评价。这三个集合的划分，并没有严格的准则，根据样本大小不同而做不同的选择，但是一个原则是测试集需要保持未知和与训练集、验证集的<strong>独立性</strong>。</p><h1 id="为什么需要模型选择">I. 为什么需要模型选择</h1><ol style="list-style-type: decimal"><li>训练误差和测试误差的波动是由训练样本的变化带来的。在理想的实验条件下，为了能公正地衡量模型的预测能力，通常需要<strong>多换几组训练集和测试集来综合评价模型的预测能力</strong>，这样的结果才可能让人更信服模型的预测能力，而不是偶然结果。实际情况中，我们手边通常可能只有一个训练集，实际的需求是在此训练集上模型做到最好，即希望在当前训练集下获取最佳的预测能力。换句话说，很多时候人们给你一个训练集就希望你能够给他一个相对最稳定的预测模型，这个目标相对获取平均预测误差来说更难，后续模型选择方法比如 CV 法、bootstrap 法、Cp 法等其实都是估计测试误差的期望。</li><li>随着模型复杂度增加，训练误差波动降低，平均训练误差降低趋向于 0，而测试误差波动上升，平均测试误差先降低后升高。这个现象说明<strong>训练误差不能代替测试误差</strong>来作为模型选择和评价的手段。<a href="https://cosx.org/2015/08/some-basic-ideas-and-methods-of-model-selection/">造成预测误差变化趋势的原因是什么？</a></li><li>用更通俗的话说，复杂的模型可能在训练集上拟合的很好，但是面对新的测试集，预测误差不降反升，发生了所谓的 “<strong>过拟合</strong>” 现象。如果一个模型在不同的测试集上测试结果不仅波动性大，而且预测误差也比较大，就要警惕发生了过拟合现象，此时不妨将模型的复杂度降低些（关于模型的复杂度含义下文会做更细致的说明），即使用变量更少的简单模型，比如线性模型。<ul><li>过拟合的原因有很多，其中一个很可能的原因是，随着模型复杂度升高，对于训练数据刻画的很细，但是训练数据中可能某些特征仅出现过一次或者很少，信息不足，而测试集中该特征却出现了很多其他的值，虽然模型在训练集上刻画的足够细致，但是由于测试集的变动，模型反而往测试机上的迁移性能下降，训练误差变化并不正比于测试误差。</li></ul></li></ol><p>最标准的方法自然在训练集上训练模型，然后在验证集上获取预测误差，该误差也被称作“样本外（extra-sample）误差”，可真实反映出模型的样本外的预测能力，最后选择最小预测误差所对应的模型作为最佳模型即可。但通常而言，<strong>独立的验证集我们也没有，手头仅有的信息就是训练集</strong>，那么要想估计测试误差或者其期望曲线，就只能在训练集上做文章，一般而言可能仅有两种思路：</p><ul><li>从训练集划分点数据出来形成验证集来近似测试误差；</li><li>只要对训练集进行合适的划分，我们就有可能近似出预测误差。但是对原始训练集划分为新的训练集和验证集，不同的划分比例可能使得新训练集与原训练集相差较大，进而使得差异很大，因此用这种划分的方式来估计条件期望形式的预测误差比较困难。那么此时我们<strong>可以不估计转为估计其期望</strong>，即平均预测误差，通过重复抽样的方式来多次估计预测误差，然后取其平均即可，这种方式我们可以称其为“<strong>重复抽样法</strong>”：通过训练集多次切分、抽样来模拟训练集、验证集，计算多个“样本外误差”，然后求其平均预测误差，这是一种密集计算型方法，比如交叉验证（Cross Validation）、自助法（bootstrap）等。</li><li>对训练误差进行某种转化来近似测试误差。</li><li>更加考虑计算效率，因为重复抽样需要计算多次估计，因此做一次模型选择可能需要花费不少时间，如果单单从训练集的训练误差就可以近似出测试误差，那么模型选择效率便会大大提高。这种方式<strong>以统计学中的 AIC、BIC 等为代表，深刻剖析训练误差与之前提到的 “样本内（in-sample）误差”、预测误差间的关系，给出了预测误差估计的解析式</strong>，因此第二种思路我们可以称之为 “解析法”。</li></ul><h1 id="模型选择">II. 模型选择</h1><p>对模型选择和模型评价的指导可以凝缩为一句话：<strong>根据已知的训练集和验证集在特定模型空间中进行模型选择，获取合适复杂度的模型，然后在多种模型空间做模型选择获取多种模型，最后的最优模型需要通过多个独立未知的测试集来做模型评价决定，否则很容易导致模型过拟合</strong>。（这实际上就是一个完整而规范的机器学习过程。）</p><p>从 “偏移 - 方差” 分解可以看到，在有限的模型空间中，对某个模型类控制好模型的复杂度非常重要，否则不容易获取较好（包含稳定与预测误差小两方面）的预测模型，这便是模型选择阶段的工作。</p><ul><li>如果你的数据集是多个混合变量，那么你就不应该选择自动模型选择方法，因为你应该不想在同一时间把所有变量放在同一个模型中。</li><li>它也将取决于你的目的。可能会出现这样的情况，一个不太强大的模型与具有高度统计学意义的模型相比，更易于实现。</li><li>回归正则化方法（Lasso，Ridge和ElasticNet）在高维和数据集变量之间多重共线性情况下运行良好。</li></ul><h2 id="评价指标">II.I. 评价指标</h2><p>在模型选择阶段，比较适合于不同模型的优点，我们可以<strong>分析不同的指标参数</strong>，如统计意义的参数，R-square，Adjusted R-square，AIC，BIC以及误差项，另一个是<strong>Mallows’Cp准则</strong>。这个主要是通过将模型与所有可能的子模型进行对比（或谨慎选择他们），检查在你的模型中可能出现的偏差。常见的指标有 AIC 准则、BIC 准则、CV 值、结构风险上界等比较普适的准则。</p><p>而在模型评价阶段，我们可以根据分类、回归、排序等不同问题关心的问题选择不同的评价指标，多与模型选择时的损失不同：（1）分类：ROC、AUC、TPR、FPR、F1 score；（2）排序：DCG、NDCG；（3）回归：RMSE、MAE、Deviance。</p><p>根据具体业务，实际的评价指标有很多种，最好的方式当然是模型选择时即设计其损失函数即为评价指标，但是通常而言这些指标包含了某些非线性变化，优化起来难度颇大，因此实际模型选择仍是选用经典的那些损失函数，而模型评价则会与其略有不同。</p><p>一般而言模型选择准则有如下几种：</p><ul><li>重复抽样与预测稳定性角度：CV、GCV、Boostrap。<strong>交叉验证</strong> 是评估预测模型最好方法。在这里，将你的数据集分成两份（一份做训练和一份做验证）。使用观测值和预测值之间的一个简单均方差来衡量你的预测精度。</li><li>似然与模型复杂度角度：AIC、AICc、BIC、EBIC</li><li>VC 维与风险上界控制角度：SRM</li></ul><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在机器学习中，有一种叫做“没有免费的午餐”的定理，即没有任何一种ML算法在处理所有问题的时候都适合。不同ML算法的性能很大程度上取决于数据的大小和结构。模型的预测能力通常也被称作模型的泛化能力，表示模型在新的、独立的测试数据上的预测能力。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>Parameter Selection</title>
    <link href="http://saili.science/parameter-selection/"/>
    <id>http://saili.science/parameter-selection/</id>
    <published>2018-05-12T07:57:08.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>模型的参数可分成两类：参数与超参数，前者是模型通过自身的训练学习得到的参数数据；后者则需要通过自身经验设置，以提高模型训练的效果。如神经网络中的隐层个数、每个隐层神经元个数、采用什么激活函数及学习算法、学习率以及正则化系数等都属于超参数。</p><span id="more"></span><p>一个模型的落地流程如下：</p><ol style="list-style-type: decimal"><li>收集日志，并从日志中抽象出特征，再把特征喂给模型，模型在初始的超参数指导下学习第一类参数；</li><li>通过离线效果指标评估超参数的设定是否合适；</li><li>若不合适则继续不断调整。</li></ol><p>在这个调参过程中主要有 2 个难点：</p><ol style="list-style-type: decimal"><li>参数空间大，尝试成本高。在工业界往往数据规模巨大、模型复杂，计算成本很高，并且每个类型的超参数都有众多选择。</li><li>目标模型是黑盒。在搜索超参数的过程中只能看到模型的输入和输出，无法获取模型内部信息（如梯度等），亦无法直接对最优超参数组合建立目标函数进行优化。</li></ol><h1 id="超参数选择方法">I. 超参数选择方法</h1><p>业界常用的搜索超参数方法主要有网格搜索、随机搜索和贝叶斯优化。</p><h2 id="网格搜索">I.I. 网格搜索</h2><p>网格搜索（Grid Search）是指在所有候选的参数选择中，通过循环遍历尝试每一种可能性，表现最好的参数就是最终的结果。</p><p>举个例子，有两类超参数，每类超参数有 3 个待探索的值，对它们进行笛卡尔积后得到 9 个超参数组合，通过网格搜索使用每种组合来训练模型，并在验证集上挑选出最好的超参数。</p><p>网格搜索算法思路及实现方式都很简单，但经过笛卡尔积组合后会扩大搜索空间，并且在存在某种不重要的超参数的情况下，网格搜索会浪费大量的时间及空间做无用功，因此它只适用于超参数数量小的情况。</p><h2 id="随机搜索">I.II. 随机搜索</h2><p>针对网格搜索的不足，Bengio 等人提出了随机搜索（Random Search）方法<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>。随机搜索首先为每类超参数定义一个边缘分布，通常取均匀分布，然后在这些参数上采样进行搜索。</p><p>随机搜索虽然有随机因素导致搜索结果可能特别差，但是也可能效果特别好。总体来说效率比网格搜索更高，但是不保证一定能找到比较好的超参数。</p><h2 id="贝叶斯优化">I.III. 贝叶斯优化</h2><p>举个简单的例子，假设关于模型最优超参数组合的函数是一维曲线，由于它是一个黑盒无法直到具体的函数形式，但是可以输入某些值并得到输出。我们随机尝试了 4 个超参数，并得到了对应的性能指标，如下图所示<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20190729125349.png"></p><p>那么问题来了，最优超参数可能在哪里？下一个待探索的超参数是哪个？而每个人猜测的是不一样的，因此每次生成的函数也不同：</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmacy1g1j20e4099mz6.jpg"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmb4x4o7j20e9097aev.jpg"></p><p>可以看到大部分都认为最优超参数是在第 3 个点附近， 由于开始时在右侧采点的离线指标是最差的，所以先验认为最优超参数在这里的可能性不大。接着把这个过程取极限，就会得到一个关于最优超参数的概率分布。假设每个分布都是高斯分布，那么得到的是一个高斯过程，其中高斯分布的均值为 0，方差大概为 5。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmbqiit1j20dk08tgnh.jpg"></p><p>这样无论我们猜测最优超参数是取哪个值，总能得到一个关于超参数好坏的描述，即是均值和方差，这里实际上我们用一个无限维的高斯过程来模拟黑盒的超参数搜索的目标函数形式。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmclb1caj20er05n0v9.jpg"></p><p>总结来说，超参数搜索问题其实是一个黑盒优化问题，贝叶斯优化通过无限维的高斯过程来描述黑盒，在这个高斯过程中可以得到每一组输入超参数的均值和方差。</p><p>得到了均值和方差则解决了上文提到的第一个问题：「最优超参数可能在哪里？」，那么下一个待探索的超参数是哪个？这其实是一个 E&amp;E 问题（探索与利用问题），是稳妥地在目前已有的最大值附近搜索还是在不确定性大的地方搜索？后者效果可能很差，但也可能有意想不到的收获。而 Acquisition function 正是平衡 E&amp;E 问题的方式。</p><ul><li>Upper (lower) Confidence Band 方法用线性加权的方式直接对 E&amp;E 采样进行平衡，第一项是当前最好的超参数值，在当前最好的结果附近稳妥的搜索；第二项是方差，表示去探索更未知的空间，beta 参数用来控制力度，这种方法简单有效。</li><li>Maximum Probability of Improvement 方法的目的是下一个待搜索的值能最大限度提升概率，假设当前最好的是 y_best, 那么 MPI 表示的是下一个待搜索的点能比 y_best 小的概率，这种方法容易陷入在局部最小值附近。</li><li>Expected Improvement 描述的是下一个待搜索的点能比当前最好的值更好的期望，因为是高斯过程，这里的后验概率是高斯形式，积分有闭式解，实现起来较为简单，因此这种方法也较为常用。</li></ul><p>可以看出贝叶斯优化（Bayesian Optimization）是通过 acquisition function 平衡均值和方差，做 E&amp;E 问题探索下一个可能的最优超参数。</p><h3 id="实例1">I.III.I. 实例1</h3><p>如上方图所示，虚线代表关于最优超参数的真实函数形式（但实际上它是个黑盒，不知道其具体形式），实线代表当前最好的超参所在位置，两条浅灰线表示的是当前点的方差。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmklr1ldj20eg09g75w.jpg"></p><p>下方图表示已知的和待探索超参数的 Expected Improvement，此时很多地方都有希望能取得比当前最好值更好的超参数，主要需要探索，我们首先选择 0.0 点作为下一个待探索的超参数。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmkvex6sj20eh09fabx.jpg"></p><p>可以看到，此时 0.0 点的方差变为 0。继续寻找下一个待探索的超参数，选择 1.0。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmla95ztj20ej09ggnr.jpg"></p><p>如图，1.0 点的方差变为 0，经过两次探索我们注意到不需要再探索右侧区域，因为我们在右边得到的超参数效果比左边的差。继续选择下一个超参数位置，选择 0.25 点左右的位置。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmlkta65j20er09kdi8.jpg"></p><p>按照 EI 方法，依次寻找下一个待探索的超参数，这次我们选择的超参数位置大概在 0.7 点。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmluu7daj20en09jdi0.jpg"></p><p>选择 0.7 点的超参数效果比之前选择的更好，此时 Expected Improvement acquision 建议应该加大在 0.7 附近搜索的力度。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmm44e8dj20en09i0un.jpg"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmmdy6doj20eq09lq4t.jpg"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dly1fwsmmjijpij20er09kjt6.jpg"></p><p>经过几轮探索之后发现最优超参数应该在 0.8 点附近。</p><h1 id="svm-parameter-selection">II. SVM Parameter Selection</h1><p>Support Vector Regression, which evolved from the support vector classification for doing regression tasks by introduction of the <span class="math inline">\(\varepsilon\)</span>-insensitive loss function, is a data-driven machine learning methodology.</p><p>The parameter <span class="math inline">\(C\)</span> controls the trade-off between the complexity of the function and the frequency in which errors are allowed. The parameter <span class="math inline">\(\sigma\)</span> affects the mapping transformation of the input data to the feature space and controls the complexity of the model, thus, it is important to select suitable parameters, and the value of parameter <span class="math inline">\(\sigma\)</span> should be selected more carefully than <span class="math inline">\(C\)</span> .</p><div class="note info"><p>Li, S., Fang, H. &amp; Liu, X., 2018. Parameter optimization of support vector regression based on sine cosine algorithm. Expert Systems with Applications, 91, pp.63–77. Available at: http://dx.doi.org/10.1016/j.eswa.2017.08.038.</p></div><div class="note info"><p>Li, S., Fang, H., 2017. A WOA-based algorithm for parameter optimization of support vector regression and its application to condition prognostics. 2017 36th Chinese Control Conference (CCC). Available at: http://dx.doi.org/10.23919/chicc.2017.8028516.</p></div><h2 id="metaheuristics">II.I. Metaheuristics</h2><ul><li><a href="https://github.com/faruto/Libsvm-FarutoUltimate-Version">libsvm matlab implement</a></li><li><a href="http://yarpiz.com/category/metaheuristics">Metaheuristics implement in Matlab&amp;Python</a></li></ul><p>The matlab samples for svm parameter selection can be found in my <a href="https://github.com/sli1989/svm-parameter-selection">Source repository</a>.</p><p>To be continued...</p><div class="footnotes"><hr><ol><li id="fn1"><p>http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf<a href="#fnref1">↩</a></p></li><li id="fn2"><p>http://gpss.cc/gpmc17/slides/LancasterMasterclass_1.pdf<a href="#fnref2">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;模型的参数可分成两类：参数与超参数，前者是模型通过自身的训练学习得到的参数数据；后者则需要通过自身经验设置，以提高模型训练的效果。如神经网络中的隐层个数、每个隐层神经元个数、采用什么激活函数及学习算法、学习率以及正则化系数等都属于超参数。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
    <category term="OptimizationAlgorithm" scheme="http://saili.science/tags/OptimizationAlgorithm/"/>
    
  </entry>
  
  <entry>
    <title>Spark 安装与使用教程</title>
    <link href="http://saili.science/spark/"/>
    <id>http://saili.science/spark/</id>
    <published>2018-04-13T10:28:52.000Z</published>
    <updated>2018-04-13T10:43:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>Spark作为一个基于内存的开源计算框架，在这个大数据时代背景下，受到越来越多的开发者的喜爱，相对于Hadoop,Spark拥有对大量数据更快的处理速度，并且易于使用（支持多种开发语言）。</p><span id="more"></span><h1 id="安装">I. 安装</h1><blockquote><p><a href="https://blog.csdn.net/nxw_tsp/article/details/78281533">大数据时代--windows下spark的安装与配置教程</a><br><a href="https://blog.csdn.net/Yt7589/article/details/62039555">spark 2.1.0安装指南完整版</a></p></blockquote><ol style="list-style-type: decimal"><li>Spark是用Scala写的，安装<a href="http://www.scala-lang.org/download/all.html">Scala</a>，注意Scala版本与Spark版本之间的版本要求。</li><li>安装<a href="http://spark.apache.org/downloads.html">Spark</a>。</li><li>因为Spark是基于Hadoop的，下载 <a href="https://archive.apache.org/dist/hadoop/common/">Hadoop</a>。</li></ol><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;Spark作为一个基于内存的开源计算框架，在这个大数据时代背景下，受到越来越多的开发者的喜爱，相对于Hadoop,Spark拥有对大量数据更快的处理速度，并且易于使用（支持多种开发语言）。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://saili.science/categories/Programming/"/>
    
    <category term="Spark" scheme="http://saili.science/categories/Programming/Spark/"/>
    
    
    <category term="Spark" scheme="http://saili.science/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>机器学习</title>
    <link href="http://saili.science/machine-learning/"/>
    <id>http://saili.science/machine-learning/</id>
    <published>2018-03-23T08:46:05.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习（Machine Learning，常简称为ML）研究的是计算机怎样模拟人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构使之不断改善自身。简单一点说，就是计算机从数据中学习出规律和模式，以应用在新数据上做预测的任务。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。</p><span id="more"></span><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65gy1foo3vai8r0j30h2090glt.jpg" alt="人工智能关系图"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/006V2m65gy1fogasefrboj312g1wtk0l.jpg" alt="机器学习框架图"></p><ul><li>它是人工智能（Artificial Intelligence，常简称为AI）的一个重要子领域，而人工智能又与更广泛的数据挖掘（Data Mining，常简称为DM）和知识发现（Knowledge Discovery in Database，常简称为KDD）领域相交叉。</li><li>机器学习是人工智能的一个分支。人工智能的研究是从以“推理”为重点到以“知识”为重点，再到以“学习”为重点，一条自然、清晰的脉络。</li><li>机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。</li><li>机器学习是人工智能的核心，应用遍及人工智能的各个领域，</li></ul><p>机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。为此，机器学习主要关注于模式识别。机器学习有助于识别数据集内的模式，并因此尝试根据现有数据进行预测。<a href="https://sli1989.github.io/deep-learning-1/">深度学习</a>是一种实现机器学习的技术<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>。</p><p>一个简单的数学建模，我们需要考虑的是：1. 要做什么？2. 怎么做？3. 这样做合理吗？4. 如果这样做，假设那些可以改变？5. 这样做需要用到那些模型？6. 这种模型简洁吗？7. 确定了这种模型，怎么求解？8. 求解出来了，与现实合理吗？9. 在这个模型中，存在什么缺点，怎么去优化？10. 总结。</p><h1 id="发展过程">I. 发展过程</h1><p>目前机器学习已经在数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、DNA序列测序、战略游戏和机器人等多个方面都得到了运用。</p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dgy1g0bvn0r77uj20m80cigoj.jpg"></p><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/645f3b4dgy1g0bvt3avxvj20gy0a7tbt.jpg"></p><h1 id="实现过程">II. 实现过程</h1><p>华盛顿大学 eScience Institute 和 Institute for Neuroengineering 的数据科学博士后 Michael Beyeler<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>介绍了如何依靠已有的方法（模型选择和超参数调节）去指导你更好地去选择算法。</p><ol style="list-style-type: decimal"><li>了解基本知识。机器学习里面三个主要类别：监督学习，无监督学习和强化学习。<ul><li>在监督学习（supervised learning）中，每个数据点都会获得标注，如类别标签或与数值相关的标签。一个类别标签的例子：将图片分类为「猫」或「狗」；数值标签的例子如：预测一辆二手车的售价。监督学习的目的是通过学习许多有标签的样本，然后对新的数据做出预测。例如，准确识别新照片上的动物（分类）或者预测二手车的售价（回归）。</li><li>在无监督性学习（unsupervised learning）中，数据点没有相关的标签。相反，无监督学习算法的目标是以某种方式组织数据，然后找出数据中存在的内在结构。这包括将数据进行聚类，或者找到更简单的方式处理复杂数据，使复杂数据看起来更简单。</li><li>在强化学习（reinforcement learning）中，算法会针对每个数据点来做出决策（下一步该做什么）。这种技术在机器人学中很常用。传感器一次从外界读取一个数据点，算法必须决定机器人下一步该做什么。强化学习也适合用于物联网应用。在这里，学习算法将收到奖励信号，表明所做决定的好坏，为了获得最高的奖励，算法必须修改相应的策略。</li></ul></li><li>对问题进行分类<ul><li>根据输入数据分类：如果我们的数据有标签，这就是一个监督学习问题；如果数据没有标签而且我们想找出数据的内在结构，那这就是无监督学习；如果我们想通过与环境交互来优化目标函数，这是强化学习。</li><li>根据输出结果分类：如果模型输出结果是一个数值，这是回归问题；如果输出结果是一个类别，这是分类问题；如果输出结果是一组输入数据，那这是聚类问题。</li></ul></li><li>寻找可用的算法。</li><li><strong>数据特征探索工程</strong>。或许比选择算法更重要的是正确选择表示数据的特征。虽然大多数特征的有效性需要靠实验来评估，但是了解常见的选取数据特征的方法是很有帮助的。这里有几个较好的方法：<ul><li>主成分分析（PCA）：一种线性降维方法，可以找出包含信息量较高的特征主成分，可以解释数据中的大多数方差。</li><li>尺度不变特征变换（SIFT）：计算机视觉领域中的一种有专利的算法，用以检测和描述图片的局部特征。它有一个开源的替代方法 ORB（Oriented FAST and rotated BRIEF）。</li><li>加速稳健特征（SURF）：SIFT 的更稳健版本，有专利。</li><li>方向梯度直方图（HOG）：一种特征描述方法，在计算机视觉中用于计数一张图像中局部部分的梯度方向的 occurrence。</li><li>智能的特征选择<ul><li>前向搜索：</li><li>最开始不选取任何特征。</li><li>然后选择最相关的特征，将这个特征加入到已有特征；计算模型的交叉验证误差，重复选取其它所有候选特征；最后，选取能使你交叉验证误差最小特征，并放入已选择的特征之中。</li><li>重复，直到达到期望数量的特征为止！</li><li>反向搜索：</li><li>从所有特征开始。</li><li>先移除最不相关的特征，然后计算模型的交叉验证误差；对其它所有候选特征，重复这一过程；最后，移除使交叉验证误差最大的候选特征。</li><li>重复，直到达到期望数量的特征为止！</li></ul></li></ul></li><li>实现所有适用的算法，模型选择。<ul><li>对于任何给定的问题，通常有多种候选算法可以完成这项工作。那么我们如何知道选择哪一个呢？通常，这个问题的答案并不简单，所以我们必须反复试验。原型开发最好分两步完成。在第一步中，我们希望通过最小量的特征工程快速且粗糙地实现一些算法。在这个阶段，我们主要的目标是大概了解哪个算法表现得更好。</li><li>一旦我们将列表减少至几个候选算法，真正的原型开发开始了。理想情况下，我们会建立一个机器学习流程，使用一组经过仔细选择的评估标准来比较每个算法在数据集上的表现。</li></ul></li><li>超参数优化。例如，主成分分析中的主成分个数，k 近邻算法的参数 k，或者是神经网络中的层数和学习速率。最好的方法是使用交叉验证来选择。</li></ol><h1 id="学习方式">III. 学习方式</h1><h2 id="离线学习与在线学习">III.I. 离线学习与在线学习</h2><p>机器学习算法可以分成两类。离线学习和在线学习。<a href="https://sli1989.github.io/online-learning/">在线机器学习</a>指每次通过一个训练实例学习模型的学习方法。</p><h2 id="主动学习与直推学习">III.II. 主动学习与直推学习</h2><h3 id="主动学习">III.II.I. 主动学习</h3><p>主动学习（active learning），指的是这样一种学习方法：有的时候，有类标的数据比较稀少而没有类标的数据是相当丰富的，但是对数据进行人工标注又非常昂贵，这时候，学习算法可以主动地提出一些标注请求，将一些经过筛选的数据提交给专家进行标注。这个筛选过程也就是主动学习主要研究的地方了，怎么样筛选数据才能使得请求标注的次数尽量少而最终的结果又尽量好。</p><p>主动学习的过程大致是这样的，有一个已经标好类标的数据集K（初始时可能为空），和还没有标记的数据集U，通过K集合的信息，找出一个U的子集C，提出标注请求，待专家将数据集C标注完成后加入到K集合中，进行下一次迭代。</p><p>按wiki上所描述的看，<strong>主动学习也属于半监督学习的范畴了，但实际上是不一样的，半监督学习和直推学习（transductive learning）以及主动学习，都属于利用未标记数据的学习技术，但基本思想还是有区别的</strong>。</p><p>如上所述，主动学习的“主动”，指的是主动提出标注请求，也就是说，还是需要一个外在的能够对其请求进行标注的实体（通常就是相关领域人员），即主动学习是交互进行的。而半监督学习，特指的是学习算法不需要人工的干预，基于自身对未标记数据加以利用。</p><h3 id="直推学习">III.II.II. 直推学习</h3><p>它与半监督学习一样不需要人工干预，不同的是，直推学习假设未标记的数据就是最终要用来测试的数据，学习的目的就是在这些数据上取得最佳泛化能力。相对应的，半监督学习在学习时并不知道最终的测试用例是什么。也就是说，直推学习其实类似于半监督学习的一个子问题，或者说是一个特殊化的半监督学习，所以也有人将其归为半监督学习。</p><h2 id="强化学习">III.III. 强化学习</h2><p>所谓强化学习就是智能系统从环境到行为映射的学习，以使奖励信号（强化信号）函数值最大，强化学习不同于连接主义学习中的监督学习，主要表现在教师信号上，强化学习中由环境提供的强化信号是对产生动作的好坏作一种评价（通常为标量信号），而不是告诉强化学习系统RLS（reinforcement learning system）如何去产生正确的动作。由于外部环境提供的信息很少，RLS必须靠自身的经历进行学习。通过这种方式，RLS在行动-评价的环境中获得知识，改进行动方案以适应环境。</p><p>在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈 到模型，模型必须对此立刻作出调整。设计一个回报函数（reward function），如果learning agent（如上面的四足机器人、象棋AI程序）在决定一步后，获得了较好的结果，那么我们给agent一些回报（比如回报函数结果为正），得到较差的结果，那么回报函数为负。比如，四足机器人，如果他向前走了一步（接近目标），那么回报函数为正，后退为负。如果我们能够对每一步进行评价，得到相应的回报函数，那么就好办了，我们只需要找到一条回报值最大的路径（每步的回报之和最大），就认为是最佳的路径。</p><p>常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning以及时间差学习（Temporal difference learning）</p><h2 id="迁移学习">III.IV. 迁移学习</h2><p>在传统的机器学习的框架下，学习的任务就是在给定充分训练数据的基础上来学习一个分类模型；然后利用这个学习到的模型来对测试文档进行分类与预测。然而，我们看到机器学习算法在当前的Web挖掘研究中存在着一个关键的问题：一些新出现的领域中的大量训练数据非常难得到。我们看到Web应用领域的发展非常快速。大量新的领域不断涌现，从传统的新闻，到网页，到图片，再到博客、播客等等。传统的机器学习需要对每个领域都标定大量训练数据，这将会耗费大量的人力与物力。而没有大量的标注数据，会使得很多与学习相关研究与应用无法开展。其次，传统的机器学习假设训练数据与测试数据服从相同的数据分布。然而，在许多情况下，这种同分布假设并不满足。通常可能发生的情况如训练数据过期。这往往需要我们去重新标注大量的训练数据以满足我们训练的需要，但标注新数据是非常昂贵的，需要大量的人力与物力。从另外一个角度上看，如果我们有了大量的、在不同分布下的训练数据，完全丢弃这些数据也是非常浪费的。如何合理的利用这些数据就是迁移学习主要解决的问题。迁移学习可以从现有的数据中迁移知识，用来帮助将来的学习。</p><p>迁移学习（Transfer Learning）的目标就是将从一个环境中学到的知识用来帮助新环境中的学习任务。因此，迁移学习不会像传统机器学习那样作同分布假设。举一个通俗的例子，一个会下象棋的人可以更容易的学会下围棋；一个认识桌子的人可以更加容易的认识椅子；</p><p>在迁移学习方面的工作目前可以分为以下三个部分：同构空间下基于实例的迁移学习，同构空间下基于特征的迁移学习与异构空间下的迁移学习。基于实例的迁移学习有更强的知识迁移能力，基于特征的迁移学习具有更广泛的知识迁移能力，而异构空间的迁移具有广泛的学习与扩展能力。</p><p>迁移学习即一种学习对另一种学习的影响，它广泛地存在于知识、技能、态度和行为规范的学习中。任何一种学习都要受到学习者已有知识经验、技能、态度等的影响，只要有学习，就有迁移。迁移是学习的继续和巩固，又是提高和深化学习的条件，学习与迁移不可分割。对于人工智能的发展路径，很多人可能对基于大数据的人工智能很熟悉，但其实还有基于小样本的尝试和迁移，这也是人工智能的一种路径。</p><h1 id="实用建议">IV. 实用建议</h1><p>总结了机器学习研究者和从业者的宝贵经验<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>，其中包括需要避免的陷阱、值得关注的重点问题、常见问题的答案：</p><ol style="list-style-type: decimal"><li>并非所有的问题都适合用机器学习解决（很多逻辑清晰的问题用规则能很高效和准确地处理），也没有一个机器学习算法可以通用于所有问题。从功能的角度分类，机器学习在一定量级的数据上，可以解决下列问题：分类、回归、聚类。</li><li>快速选择开发/测试集——如果有必要不要害怕更换。思考清理贴错标签的开发/测试集是否值得。考虑将开发集分为多个子集。</li><li>学习=表征+评估+优化。一个相关的问题是如何表征输入，即使用哪些特征。需要一个评估函数来区分分类器的好坏。我们要用一种方法搜索得分最高的分类器。</li><li>泛化能力很关键。</li><li>选择正确的评估指标。</li><li>仅有数据是不够的。机器学习并非魔术，它无法做到无中生有，它所做的是举一反三。</li><li>过拟合具有多面性。理解过拟合的一种方法是将泛化的误差进行分解，分为偏差和方差。除交叉验证之外，还有很多方法可以解决过拟合问题。最流行的是在评估函数中增加一个正则化项。</li><li>高维度会挫伤直觉。</li><li>理论保证与实际的出入。</li><li>特征工程是关键。</li><li>数据量为王。</li><li>不单单学习一个模型。</li><li>简单不意味着准确。</li><li>可表征并不意味着可学习。</li><li>相关性并不意味着因果关系。</li><li>机器学习是一个迭代过程：不要指望第一次就成功。快速构建第一个系统，然后迭代。并行评估多个想法。</li></ol><h1 id="学习资源">V. 学习资源</h1><p><a href="https://towardsdatascience.com/the-whos-who-of-machine-learning-and-why-you-should-know-them-9cefbbc84f07">The Who’s Who Of Machine Learning, And Why You Should Know Them</a></p><p>机器学习里所说的“算法”与程序员所说的“数据结构与算法分析”里的“算法”略有区别。前者更关注结果数据的召回率、精确度、准确性等方面，后者更关注执行过程的时间复杂度、空间复杂度等方面。 当然，实际机器学习问题中，对效率和资源占用的考量是不可或缺的。</p><p>『数学基础』『典型机器学习算法』『编程基础』三个并行的部分，是因为机器学习是一个将数学/算法理论和工程实践紧密结合的领域，需要扎实的理论基础帮助引导数据分析与模型调优，同时也需要精湛的工程开发能力去高效化地训练和部署模型和服务。（每一个算法，要在训练集上最大程度拟合同时又保证泛化能力，需要不断分析结果和数据，调优参数，这需要我们对数据分布和模型底层的数学原理有一定的理解。）。具备了机器学习的必要条件，剩下的就是怎么运用它们去做一个完整的机器学习项目。其工作流程如下: 抽象成数学问题—— 获取数据——特征预处理与特征选择——训练模型与调优——模型诊断——模型融合——上线运行。</p><p>入门系列：</p><ul><li><a href="https://www.jiqizhixin.com/articles/2018-04-12-4">读懂机器学习需要哪些数学知识</a></li><li>机器学习 新手快速入门 <a href="https://pan.baidu.com/s/1tNXYQNadAsDGfPvuuj7_Tw">Getting Started With MachineLearning (all in one).pdf</a></li><li>Andrew Ng（中文名：吴恩达）自2002年获得博士学位以来，Andrew Ng一直在斯坦福任教。他创建并领导了谷歌大脑团队，该团队被认为是世界上最先进的ML/AI研究机构之一。<ul><li><a href="https://codeburst.io/my-first-step-into-machine-learning-23d2b071560e">My First Step Into Machine Learning</a>。</li><li>Andrew Ng所拍摄的<a href="https://www.youtube.com/watch?list=PLfsVAYSMwsksjfpy8P2t_I52mugGeA5gR&amp;v=-eyhCTvrEtE">《深度学习的英雄》(the heroes of deeplearning)的采访列表</a>。</li><li>吴恩达的新书<a href="http://www.mlyearning.org/">Machine Learning Yearning</a>，是Ng在机器学习工程实践中的经验总结，非常实用且独一无二的一本书，短小精悍但干货十足，强烈推荐给从事数据领域的团队与个人。</li></ul></li><li>Geoffrey Hinton被称为AI教父，是神经网络领域的首批研究者之一。当他是卡内基梅隆大学的教授时，他是最早证明广义反向传播算法的研究者之一。在Andrew Ng的引导下，他在coursera上发布了他的<a href="https://www.coursera.org/learn/neural-networks">神经网络课程</a>，这是一个巨大的成功。</li><li>2014年，Ian Goodfellow发表了一篇关于<a href="https://medium.com/@ekss1121/generative-adversarial-networks-b9f80e6d7679">GANs</a>的论文，这是AI行业的一个突破。GANs基本上允许计算机进行想象，计算机可以训练与我们提供给它的模型相似的模型。</li><li>Yann LeCun发明了卷积神经网络，如果没有他的贡献，图像识别领域就不会有进展。<a href="https://www.youtube.com/watch?v=rtGXv88UQ-c">关于人工智能未来的一个有趣的演讲</a>。</li></ul><p>个人博客系列：</p><ul><li><a href="http://120.79.254.53/">统计学习方法– weng-JJ技术小站</a></li></ul><p>免费机器学习书籍<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a><a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>：</p><ul><li><a href="http://brohrer.github.io/blog.html">Data Science and Robots-Brandon Rohrer</a></li><li>2018年3月1日，Google上线了AI学习网站——Learn with Google AI，并重磅推出了<a href="https://developers.google.com/machine-learning/crash-course/">机器学习速成课程MLCC</a>，该课程基于TensorFlow（TF），旨在为所有经验水平的人提供免费课程、教程和动手练习。</li><li><a href="http://mmds.org/#ver21">Mining of Massive Datasets</a>，<a href="http://dmml.asu.edu/smm/">Social Media Mining</a>，</li><li><a href="https://github.com/bulutyazilim/awesome-datascience">Awesome Data Science</a>（清单），<a href="http://gael-varoquaux.info/scikit-learn-tutorial/">Scikit-Learn Tutorial: Statistical-Learning for Scientific Data Processing</a></li><li><a href="http://greenteapress.com/wp/think-bayes/">Think Bayes</a>，<a href="http://www.kareemalkaseer.com/books/ml">Machine Learning and Big Data</a>，<a href="https://web.stanford.edu/~hastie/StatLearnSparsity/">Statistical Learning with Sparsity</a>，<a href="https://leanpub.com/LittleInferenceBook">Statistical inference for data science</a>，<a href="http://stanford.edu/~boyd/cvxbook/">Convex Optimization</a>，</li><li><a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding MachineLearning: From Theory to Algorithms</a></li><li><a href="https://github.com/owainlewis/awesome-artificial-intelligence">Awesome Artificial Intelligence (AI)</a>（清单）</li><li><a href="https://github.com/josephmisiti/awesome-machine-learning">Awesome-machine-learning</a> （清单）。<a href="https://seat.massey.ac.nz/personal/s.r.marsland/MLBook.html">Machine Learning (An Algorithmic Perspective)</a></li><li><a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a>，<a href="http://www.iro.umontreal.ca/~bengioy/talks/lisbon-mlss-19juillet2015.pdf">Deep Learning</a> <a href="http://deeplearning.net/tutorial/deeplearning.pdf">Deep Learning Tutorial</a></li><li><a href="https://github.com/aikorea/awesome-rl">Awesome Reinforcement Learning</a>来自于aikorea整理的一份关于强化学习的代码、论文、应用、教程的清单。</li><li><a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning (with applications in R)</a></li><li><a href="https://github.com/jakevdp/PythonDataScienceHandbook">Python Data Science Handbook</a>，<a href="http://totoharyanto.staff.ipb.ac.id/files/2012/10/Building-Machine-Learning-Systems-with-Python-Richert-Coelho.pdf">Building Machine Learning Systems with Python</a>，<a href="https://www.nltk.org/book/">Natural Language Processing with Python</a>，<a href="https://automatetheboringstuff.com/">Automate the Boring Stuff with Python</a>，</li></ul><div id="ml-dataset"></div><h1 id="数据集">VI. 数据集</h1><blockquote><p><a href="https://www.jiqizhixin.com/articles/2018-10-24-10">机器学习高质量数据集大合辑</a></p></blockquote><div class="note info"><p>部分网址需要<a href="https://sli1989.github.io/windows-use/#goagent">科学上网配置</a>。</p></div><ul><li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research">List of datasets for machine learning research</a><br></li><li><a href="http://archive.ics.uci.edu/ml/datasets.html">UCI Machine Learning Repository: Data Sets</a>是网络上最早的数据集来源之一，是寻找各种有趣数据集的第一选择。</li><li><a href="http://www.comp-engine.org/timeseries/">Comp-Engine Time Series</a></li><li><a href="https://www.kaggle.com/datasets">Datasets | Kaggle</a>是由联合创始人、首席执行官安东尼·高德布卢姆（Anthony Goldbloom）2010年在墨尔本创立的，主要为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台。该平台已经吸引了80万名数据科学家的关注。</li><li><a href="https://www.data.gov/?spm=5176.100239.0.0.Dlz4EY">Data.gov</a></li><li><a href="https://www.analyticsvidhya.com/blog/2016/10/17-ultimate-data-science-projects-to-boost-your-knowledge-and-skills">17 Free Data Science Projects To Boost Your Knowledge &amp; Skills</a></li><li><a href="http://www.datatang.com/">数据堂</a></li><li><a href="http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/">Prognostics Center of Excellence - Data Repository</a></li><li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html">LIBSVM Data: Regression</a></li><li><a href="http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html">Regression Data Sets</a></li><li><a href="http://research.ics.aalto.fi/eiml/datasets.shtml">Environmental and Industrial Machine Learning Group</a></li><li><a href="http://keel.es/datasets.php">KEEL: A software tool to assess evolutionary algorithms for Data Mining problems (regression, classification, clustering, pattern mining and so on)</a></li><li><a href="http://www.sidc.be/silso/datafiles">Sunspot Number | SILSO</a></li><li><a href="http://hadobs.metoffice.com/hadcet/">Met Office Hadley Centre observations datasets</a></li><li><a href="http://ecdms.energy.ca.gov/">Energy Consumption Database</a></li><li><a href="https://datamarket.com/data/list/?q=provider:tsdl">Time Series Data Library - Data provider — DataMarket</a></li><li><a href="https://forecasters.org/resources/time-series-data/">Time Series Data | International Institute of Forecasters</a></li><li><a href="http://www.neural-forecasting-competition.com/datasets.htm">neural-forecasting-competition</a></li><li><a href="http://www.comp-engine.org/timeseries/browse-data-by-category/">Browse time-series data by category - Comp-Engine Time Series</a></li><li><a href="https://physionet.org/physiobank/database/">PhysioBank Databases</a></li></ul><div class="footnotes"><hr><ol><li id="fn1"><p><a href="http://blog.sciencenet.cn/blog-2888249-1082369.html">一篇文章讲清楚人工智能、机器学习和深度学习的区别和联系</a><a href="#fnref1">↩</a></p></li><li id="fn2"><p><a href="https://zhuanlan.zhihu.com/p/25459407">经验之谈：如何为你的机器学习问题选择合适的算法</a><a href="#fnref2">↩</a></p></li><li id="fn3"><p><a href="https://www.kdnuggets.com/2018/05/7-useful-suggestions-machine-learning-yearning.html">7 Useful Suggestions from Andrew Ng “Machine Learning Yearning”</a><a href="#fnref3">↩</a></p></li><li id="fn4"><p><a href="https://www.jiqizhixin.com/articles/Pedro-Domingos-12-useful-things-to-know-about-machine-learning">A Few Useful Things to Know about Machine Learning</a><a href="#fnref4">↩</a></p></li><li id="fn5"><p><a href="https://mp.weixin.qq.com/s/m9Vwc3SFZx3gv3RANJ72qA">一份最新的人工智能10大主题Github Awesome知识资料清单！值得收藏</a><a href="#fnref5">↩</a></p></li><li id="fn6"><p><a href="https://towardsdatascience.com/list-of-free-must-read-machine-learning-books-89576749d2ff">免费机器学习书籍</a><a href="#fnref6">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器学习（Machine Learning，常简称为ML）研究的是计算机怎样模拟人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构使之不断改善自身。简单一点说，就是计算机从数据中学习出规律和模式，以应用在新数据上做预测的任务。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>人工智能</title>
    <link href="http://saili.science/artificial-intelligence/"/>
    <id>http://saili.science/artificial-intelligence/</id>
    <published>2018-02-14T13:15:18.000Z</published>
    <updated>2025-07-21T06:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。人工智能的研究领域也在不断扩大，包括专家系统、机器学习、进化计算、模糊逻辑、计算机视觉、自然语言处理、推荐系统等。</p><span id="more"></span><p>人工智能研究的一个主要目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。但不同的时代、不同的人对这种“复杂工作”的理解是不同的。简言之，人类智能由三个部分构成。如果所有三个部分都可以在一台机器上复制或近似复制，那么我们就拥有了一个人工智能系统。</p><ul><li>通过多维数据源感知（Perception through a multi-dimensional data source）</li><li>对步骤1的数据中进行模式识别（Pattern recognition within the data set referred in step 1 above）</li><li>在给定的情境下做出决策（Decision making within the given context）</li></ul><p><img src="https://ghfast.top/https://raw.githubusercontent.com/sli1989/blogimg/master/img/20190418125816.png" alt="人工智能框架图"></p><blockquote><p><a href="https://medium.com/swlh/artificial-intelligence-vs-machine-learning-is-it-confusing-3ace59aa0d19">深入理解人工智能和机器学习</a></p></blockquote><p>工程师Narasimha Prasanna HN撰写的技术博文“<a href="https://mp.weixin.qq.com/s/em1NisiFmXwLmwH7_UXwWw">what-is-artificial-general-intelligence</a>”主要介绍人工智能的概念，当前人工智能的水平，以及什么是强人工智能，当前实现强人工智能的方向。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。人工智能的研究领域也在不断扩大，包括专家系统、机器学习、进化计算、模糊逻辑、计算机视觉、自然语言处理、推荐系统等。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="ArtificialIntelligence" scheme="http://saili.science/tags/ArtificialIntelligence/"/>
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>强化学习</title>
    <link href="http://saili.science/reinforcement-learning/"/>
    <id>http://saili.science/reinforcement-learning/</id>
    <published>2018-02-14T12:57:03.000Z</published>
    <updated>2018-03-23T12:25:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。这个方法具有普适性，因此在其他许多领域都有研究，例如博弈论、控制论、运筹学、信息论、仿真优化、多主体系统学习、群体智能、统计学以及遗传算法。 <span id="more"></span></p><p>人们一般认为机器学习拥有三根重要的柱石：非监督学习、监督学习、强化学习，这三个部分基本上包含了机器学习研究与应用的方方面面。在非监督学习中，算法的目标是对数据进行有效的归纳总结，我们可以把这一过程视为模型将输入的x数据转换为了可以归纳表示输入信息的低维度输出z。而对于监督学习来说、我们需要通过输入数据x预测出输出数据的某一特征y，这是我们最为熟悉的机器学习方法了，主要包括回归和分类两大分支。而对于强化学习来说，对于特定的输入x对应着两个输出分别是action和reward。强化学习的目标就是在给定输入的情况下尽可能地选择出能使r（奖励）最大的a（行为）。有很多问题可以用强化学习来解决，从游戏中的在线决策到网络世界中的最大化收益都可以通过这样的方式来获取较好的解决方案。</p><p>在<a href="http://www.argmin.net/2018/01/29/taxonomy/">An Outsider’s Tour of Reinforcement Learning</a>（<a href="https://36kr.com/p/5119373.html">中文</a>）里作者<a href="http://www.argmin.net/2018/02/05/linearization/">将强化学习归结成了一种预测分析的模式</a>，而在随后的文章里则是<a href="http://www.argmin.net/2018/02/08/lqr/">以优化控制的形式展开</a>的。</p><p>描述性分析指的是通过归纳数据使其具有更好的可解释性，非监督学习就是一种很好的描述性分析方法，而预测分析的目标则是基于现在的数据估计未来的结果，而最终的规范性分析(prescriptive analytics)则旨在指导行动以保证结果。强化学习恰恰就属于最后一个范畴。而最大的挑战则来自于规范性分析。这一类模型的目标十分清晰：强化学习和规范性分析需要分析输入并决定要采取的行动和明确对应的奖励。规范性分析所面对的新数据来源于不确定的环境中，随后需要作出决策并利用这些决策影响环境。这样的系统会在好的决策下获得丰厚的奖励，而在糟糕的决策后则面临着灾难性的结果。但由于反馈来源于复杂的相互联系中使其在理论上难以研究。</p><p>强化学习令人不解的原因主要在于它需要我们利用一种在通常机器学习中不常用的核心概念去思考。首先你需要考虑时变的统计学模型并理解数据中的依赖只是暂时的相关而已；第二、你应该理解统计学习问题中的反馈效应，每一次行为后对于结果的观测分布，强化学习系统必须适应这些分布。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。这个方法具有普适性，因此在其他许多领域都有研究，例如博弈论、控制论、运筹学、信息论、仿真优化、多主体系统学习、群体智能、统计学以及遗传算法。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
    <category term="ReinforcementLearning" scheme="http://saili.science/tags/ReinforcementLearning/"/>
    
  </entry>
  
  <entry>
    <title>凸优化</title>
    <link href="http://saili.science/convex-optimization/"/>
    <id>http://saili.science/convex-optimization/</id>
    <published>2018-02-12T07:42:44.000Z</published>
    <updated>2020-01-13T03:32:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>凸优化是指一种比较特殊的优化，是指求取最小值的目标函数为凸函数的一类优化问题。其中，目标函数为凸函数且定义域为凸集的优化问题称为无约束凸优化问题。而目标函数和不等式约束函数均为凸函数，等式约束函数为仿射函数，并且定义域为凸集的优化问题为约束优化问题。 <span id="more"></span></p><p>凸优化之所以如此重要，是因为：</p><ul><li>其应用非常广泛，机器学习中很多优化问题都要通过凸优化来求解；</li><li>在非凸优化中，凸优化同样起到重要的作用，很多非凸优化问题，可以转化为凸优化问题来解决；</li><li>如上引用所述，凸优化问题可以看作是具有成熟求解方法的问题，而其他优化问题则未必。</li></ul><p>标准优化问题</p><p>凸优化知识体系包括了<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>：</p><ul><li>凸集，定义目标函数和约束函数的定义域。</li><li>凸函数，定义优化相关函数的凸性限制。</li><li>凸优化，中心内容的标准描述。</li><li>凸优化问题求解，核心内容。相关算法，梯度下降法、牛顿法、内点法等。</li><li><a href="https://sli1989.github.io/lagrange-multiplier/">对偶问题</a>，将一般优化问题转化为凸优化问题的有效手段，求解凸优化问题的有效方法。</li></ul><h1 id="最速下降法">I. 最速下降法</h1><blockquote><p><a href="https://zhuanlan.zhihu.com/p/32709034">【最优化】一文搞懂最速下降法</a></p></blockquote><p>最速梯度下降法解决的问题是无约束优化问题，而所谓的无约束优化问题就是对目标函数的求解，没有任何的约束限制的优化问题。</p><h1 id="牛顿法">II. 牛顿法</h1><blockquote><p><a href="https://zhuanlan.zhihu.com/p/33544363">【最优化】无约束优化方法-牛顿法</a></p></blockquote><p>牛顿法思想： 用目标函数的二阶泰勒展开近似该目标函数，通过求解这个二次函数的极小值来求解凸优化的搜索方向。</p><p>牛顿法推导：<a href="https://www.jianshu.com/p/f00715396c7b">凸优化(七)——牛顿法</a></p><p>我们可以看出，牛顿法和最速梯度的不同就是在于最速梯度下降法的迭代方向是梯度的负方向，迭代步长根据一维搜索得到。而牛顿法的迭代方向为上述推导的牛顿步径，迭代步长可以看为定值1。</p><p>牛顿法的优缺点：</p><ul><li>优点是：对于二次正定函数，迭代一次即可以得到最优解，对于非二次函数，若函数二次性较强或迭代点已经进入最优点的较小邻域，则收敛速度也很快。</li><li>缺点：<ul><li>保证不了迭代方向是下降方向，这就是致命的！换句话说就是不一定迭代能够收敛，后面的阻尼牛顿法会解决这个问题，牛顿法就到此为止了。</li><li>计算量相当复杂，除需计算梯度除外，还需要计算二阶偏导数矩阵和它的逆矩阵，计算量，存储量都很大，并且都以维数N的平方比增加，当N很大的时候，计算量的问题就更加突出。</li></ul></li></ul><div class="footnotes"><hr><ol><li id="fn1"><p><a href="https://www.jianshu.com/p/fe2e7f0e89e5">凸优化</a><a href="#fnref1">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;凸优化是指一种比较特殊的优化，是指求取最小值的目标函数为凸函数的一类优化问题。其中，目标函数为凸函数且定义域为凸集的优化问题称为无约束凸优化问题。而目标函数和不等式约束函数均为凸函数，等式约束函数为仿射函数，并且定义域为凸集的优化问题为约束优化问题。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="OptimizationAlgorithm" scheme="http://saili.science/tags/OptimizationAlgorithm/"/>
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://saili.science/neural-network/"/>
    <id>http://saili.science/neural-network/</id>
    <published>2018-02-01T12:35:26.000Z</published>
    <updated>2018-07-08T06:21:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>在机器学习和认知科学领域，人工神经网络（英文：artificial neural network，缩写ANN），简称神经网络（英文：neural network，缩写NN）或类神经网络，是一种模仿生物神经网络(动物的中枢神经系统，特别是大脑)的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具。</p><span id="more"></span><blockquote><p><a href="http://neuralnetworksanddeeplearning.com/index.html">Neural Networks and Deep Learning</a></p></blockquote><p>前向算法的作用是计算输入层结点对隐藏层结点的影响，也就是说，把网络正向的走一遍：输入层—-&gt;隐藏层—-&gt;输出层,计算每个结点对其下一层结点的影响。</p><p>例如，我们要算结点h1的值，那么就是：</p><p><span class="math display">\[net_{h_{1}}=i_{1}\times w_{1}+i_{2}\times w_{2}+b_{1} \times 1\]</span></p><p>是一个简单的加权求和。这里稍微说一下，偏置项和权重项的作用是类似的，不同之处在于权重项一般以乘法的形式体现，而偏置项以加法的形式体现。</p><p>而在计算结点<span class="math inline">\(o_1\)</span>时，结点<span class="math inline">\(h_1\)</span>的输出不能简单的使用<span class="math inline">\(net_{h1}\)</span>的结果，必须要计算激活函数，激活函数，不是说要去激活什么，而是要指“激活的神经元的特征”通过函数保留并映射出来。以sigmoid函数为例，<span class="math inline">\(h_1\)</span>的输出：</p><p><span class="math display">\[out_{h_{1}}=\frac{1}{1+e^{-net_{h_{1}}}}\]</span></p><p><span class="math display">\[net_{o_{1}}=out_{h_{1}}\times w_{5}+out_{h_{2}}\times w_{6}+b_{2}\times 1\]</span></p><p><span class="math display">\[out_{o_{1}}=\frac{1}{1+e^{-net_{o_{1}}}}\]</span></p><p>按照上面的步骤计算出<span class="math inline">\(out_{o_{2}}\)</span>，则<span class="math inline">\([out_{o_{1}},out_{o_{2}}]\)</span>就是整个网络第一次前向运算之后得到的结果。</p><p>在实际情况中，因为是随机给定的权值，很大的可能（几乎是100%）得到的输出与实际结果之间的偏差非常的大，这个时候我们就需要比较我们的输出和实际结果之间的差异，将这个残差返回给整个网络，调整网络中的权重关系。这也是为什么我们在神经网络中需要后向传播的原因。其主要计算步骤如下：</p><ol style="list-style-type: decimal"><li>计算总误差 <span class="math display">\[E_{total}=\sum \frac{1}{2}(target-output)^{2}\]</span></li><li>隐藏层的权值更新</li><li>在要更新每个边的权重之前，必须要知道这条边对最后输出结果的影响，可以用整体误差对<span class="math inline">\(w_{5}\)</span>求偏导求出<span class="math inline">\(\frac{\partial E_{total}}{\partial_{w_{5}}}\)</span>。具体计算的时候，可以采用链式法则展开，在计算的时候一定要注意每个式子里面哪些自变量是什么，求导千万不要求错了。需要讲出来的一个地方是，在计算<span class="math inline">\(w_{1}\)</span>的权重时，<span class="math inline">\(E_{total}\)</span>中的两部分都需要对它进行求导，因为这条边在前向传播中对两个残差都有影响。 <span class="math display">\[\frac{\partial E_{total}}{\partial out_{o_{1}}} \times \frac{\partial out_{o_{1}}}{\partial net_{o_{1}}} \times \frac{\partial net_{o_{1}}}{\partial w_{5}}\]</span></li><li>更新权重 这一步里面就没什么东西了，直接根据学习率来更新权重： <span class="math display">\[w_5^+=w_5-\eta \times \frac{\partial E_{total}}{\partial_{w_{5}}}\]</span></li><li>至此，一次正向+反向传播过程就到此为止，接下来只需要进行迭代，不断调整边的权重，修正网络的输出和实际结果之间的偏差（也就是training整个网络）。   </li></ol><h1 id="归一化">I. 归一化</h1><p>为什么要归一化？不同的算法，在归一化中得到的好处各不相同。不过目前大部算法，都比较需要归一化，特别是常用的梯度下降法（或梯度下降的衍生方法）。</p><ul><li>使网络快速的收敛，更方便的求解。</li><li>无容置疑，归一化的确可以避免一些不必要的数值问题。</li><li>避免神经元饱和：与权值阈值相乘后，才是sigmoid的输入值，初始化得好的话，并不会饱和输出。若果使用“把权值和阈值随机初始化为[-1，1]之间的值”这种初始化方法，那不归一化就会引起神经元输出饱和现象。</li><li>大数吞小数：若果我们找到适合的权值，是不会吞掉的。</li></ul><p>关于使用matlab工具箱：</p><ol style="list-style-type: decimal"><li>Matlab2012b已经会自动将输入数据归一化，所以不必再自己去做数据的预处理，直接用原始数据建立网络就可以。</li><li>使用matlab神经网络工具箱，而又要用梯度下降法的话，输出一定要做归一化。因为工具箱计算误差的时候，使用的是原始数据的误差，因此误差数量级可能很大，这样一来梯度就很大了，在学习率还没来得及自适应减小的时候，梯度就一下子把原来初始化好的权重给吞掉了，使网络的权重掉到一个离最优解非常远的地方。</li><li>使用matlab2012b（或以上）工具箱得到的网络权值，是面向作了归一化后的数据的。所以使用时，需要先对数据进行归一化，再将归一化后的输入数据放到网络中计算网络输出，再将输出反归一化，才是真正的预测结果。由于归一化和反归一化都是线性运算，而权值阈值与输入输出也是线性运算，能否将<a href="http://www.nnetinfo.com/nninfo/showText.jsp?id=32">它们合并成一个线性运算</a>？答案当然是可以的！</li></ol><h1 id="梯度消失">II. 梯度消失</h1><blockquote><p><a href="http://blog.csdn.net/jzrita/article/details/72732037">神经网络梯度与归一化问题总结</a></p></blockquote><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在机器学习和认知科学领域，人工神经网络（英文：artificial neural network，缩写ANN），简称神经网络（英文：neural network，缩写NN）或类神经网络，是一种模仿生物神经网络(动物的中枢神经系统，特别是大脑)的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
    <category term="NeuralNetwork" scheme="http://saili.science/tags/NeuralNetwork/"/>
    
  </entry>
  
  <entry>
    <title>如何理解HTTPS</title>
    <link href="http://saili.science/https/"/>
    <id>http://saili.science/https/</id>
    <published>2018-01-20T14:17:08.000Z</published>
    <updated>2018-03-23T12:25:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>超文本传输安全协议（英语：Hypertext Transfer Protocol Secure，缩写：HTTPS，常称为HTTP over TLS，HTTP over SSL或HTTP Secure）是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，但利用SSL/TLS来加密数据包。HTTPS开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。这个协议由网景公司（Netscape）在1994年首次提出，随后扩展到互联网上。</p><span id="more"></span><p>先放结论<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>：HTTPS要使客户端与服务器端的通信过程得到安全保证，必须使用的对称加密算法，但是协商对称加密算法的过程，需要使用非对称加密算法来保证安全，然而直接使用非对称加密的过程本身也不安全，会有中间人篡改公钥的可能性，所以客户端与服务器不直接使用公钥，而是使用数字证书签发机构颁发的证书来保证非对称加密过程本身的安全。这样通过这些机制协商出一个对称加密算法，就此双方使用该算法进行加密解密。从而解决了客户端与服务器端之间的通信安全问题。</p><p>我们先从一个聊天软件说起，我们要实现A能发一个hello消息给B。要实现A发给B的hello消息包，即使被中间人拦截到了，也无法得知消息的内容。</p><ul><li>对称加密算法。只要这个密钥S不公开给第三者，同时密钥S足够安全，我们就解决了我们一开始所定问题域了。如果服务器端对所有的客户端通信都使用同样的对称加密算法，无异于没有加密。那怎么办呢？答案是：Web服务器与每个客户端使用不同的对称加密算法。</li><li>我们的服务器端通过协商告诉客户端该使用哪种对称加密算法。但是，你协商的过程是没有加密的，还是会被中间人拦截。</li><li>非对称加密。密码学领域中，有一种称为“非对称加密”的加密算法，特点是私钥加密后的密文，只要是公钥，都可以解密，但是公钥加密后的密文，只有私钥可以解密。私钥只有一个人有，而公钥可以发给所有的人。我们使用非对称加密算法进行对称加密算法协商过程。</li><li>要达到Web服务器针对每个客户端使用不同的对称加密算法，同时，我们也不能让第三者知道这个对称加密算法是什么，怎么办？就是使用随机数来生成对称加密算法。这样就可以做到服务器和客户端每次交互都是新的加密算法、只有在交互的那一该才确定加密算法。</li><li><p>如果使用非对称加密算法，我们的客户端A，B需要一开始就持有公钥。</p><ul><li>方案1. 服务器端将公钥发送给每一个客户端。如果服务器端发送公钥给客户端时，被中间人调包了，怎么办？</li><li>方案2. 服务器端将公钥放到一个远程服务器。多了一次请求，还要另外处理公钥的放置问题。</li><li>所以，我们不能直接将服务器的公钥传递给客户端，而是第三方机构使用它的私钥对我们的公钥进行加密后，再传给客户端。客户端再使用第三方机构的公钥进行解密。</li></ul></li><li>数字签名，解决同一机构颁发的不同证书被篡改问题。客户端在拿到证书后，自己就有能力分辨证书是否被篡改了。客户端拿到证书后根据证书上的方法自己生成一个证书编号，如果生成的证书编号与证书上的证书编号相同，那么说明这个证书是真实的。</li><li><p>第三方机构的公钥怎么跑到了客户端的机器中呢？现实中，浏览器和操作系统都会维护一个权威的第三方机构列表（包括它们的公钥）。因为客户端接收到的证书中会写有颁发机构，客户端就根据这个颁发机构的值在本地找相应的公钥。</p></li></ul><div class="footnotes"><hr><ol><li id="fn1"><p><a href="http://showme.codes/2017-02-20/understand-https/">也许，这样理解HTTPS更容易</a><a href="#fnref1">↩</a></p></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;超文本传输安全协议（英语：Hypertext Transfer Protocol Secure，缩写：HTTPS，常称为HTTP over TLS，HTTP over SSL或HTTP Secure）是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，但利用SSL/TLS来加密数据包。HTTPS开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。这个协议由网景公司（Netscape）在1994年首次提出，随后扩展到互联网上。&lt;/p&gt;</summary>
    
    
    
    <category term="Wiki" scheme="http://saili.science/categories/Wiki/"/>
    
    
    <category term="HTTPS" scheme="http://saili.science/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>区块链</title>
    <link href="http://saili.science/blockchain/"/>
    <id>http://saili.science/blockchain/</id>
    <published>2018-01-20T10:12:44.000Z</published>
    <updated>2018-03-23T12:25:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>区块链（英语：blockchain 或 block chain）是用分布式数据库识别、传播和记载信息的智能化对等网络, 也称为价值互联网。中本聪在2008年，于《比特币白皮书》中提出“区块链”概念，并在2009年创立了比特币社会网络，开发出第一个区块，即“创世区块”。本文根据阮一峰老师的<a href="http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html">区块链入门教程</a>整理并解释一下区块链到底是什么，有何特别之处。</p><span id="more"></span><blockquote><p><a href="https://www.zhihu.com/question/37290469">区块链是什么，如何简单易懂地介绍区块链？</a></p></blockquote><p>区块链就是一个数据库，记载了所有的交易，用作中央记账系统。每笔交易的核心，就是一句话，比如&quot;张三向李四转移了1个比特币&quot;。为了证明这句话可信，张三为它加上了数字签名。任何人都可以用张三的公钥，证明这确实是张三本人的行为。另一方面，其他人无法伪造张三的数字签名，所以不可能伪造这笔交易。矿工们收到这句话，首先验证数字签名的可信性，然后验证张三确实拥有这些比特币（每一笔交易都有上一笔交易的编号，用来查询比特币的来源）。验证通过以后，就着手把这句话写入区块链了。一旦写入区块链，所有人就都可以查询到，因此这笔比特币就被认为，从张三转移到了李四。区块链的作用就是把这句话永久保存下来了，让任何人都可以查看，并且任何人（包括张三本人在内）都无法再修改了。</p><ul><li>首先，区块链的主要作用是储存信息。任何需要保存的信息，都可以写入区块链，也可以从里面读取，所以它是数据库。</li><li>其次，任何人都可以架设服务器，加入区块链网络，成为一个节点。</li></ul><p>分布式数据库并非新发明，但是，区块链有一个革命性特点。区块链没有管理员，它是彻底无中心的。每个节点都是平等的，都保存着整个数据库。你可以向任何一个节点，写入/读取数据，所有节点最后都会同步，保证区块链一致。</p><p>区块链奇妙的地方在于怎么才能保证数据是可信。区块链由一个个区块（block）组成。区块很像数据库的记录，每次写入数据，就是创建一个区块。每个区块包含区块头（Head）和区块体（Body）。区块头包含了当前区块的多项元信息，如Hash值。正是通过这种联动机制，区块链保证了自身的可靠性，数据一旦写入，就无法被篡改。</p><ul><li>区块链的 Hash 长度是256位，这就是说，不管原始内容是什么，最后都会计算出一个256位的二进制数字。而且可以保证，只要原始内容不同，对应的 Hash 一定是不同的。</li><li>区块与 Hash 是一一对应的，每个区块的 Hash 都是针对&quot;区块头&quot;（Head）计算的。这意味着，如果当前区块的内容变了，或者上一个区块的 Hash 变了，一定会引起当前区块的 Hash 改变。</li></ul><p>由于必须保证节点之间的同步，所以新区块的添加速度不能太快。你永远只能在最新区块的后面，生成下一个区块。区块链的设计是，平均每10分钟，全网才能生成一个新区块，一小时也就六个。也就是说，只有通过极其大量的计算，才能得到当前区块的有效 Hash，从而把新区块添加到区块链。由于计算量太大，所以快不起来。这个过程就叫做采矿（mining），计算 Hash 的机器就叫做矿机，操作矿机的人就叫做矿工。</p><ul><li>区块头包含一个难度系数（difficulty），这个值决定了计算 Hash 的难度。</li><li>就算采矿很难，但也没法保证，正好十分钟产出一个区块。为了将产出速率恒定在十分钟，中本聪还设计了难度系数的动态调节机制。他规定，难度系数每两周（2016个区块）调整一次。如果这两周里面，区块的平均生成速度是9分钟，就意味着比法定速度快了10%，因此难度系数就要调高10%；如果平均生成速度是11分钟，就意味着比法定速度慢了10%，因此难度系数就要调低10%。</li><li>不是任意一个 Hash 都可以，Hash 的有效性跟目标值密切相关，只有小于目标值的 Hash 才是有效的，否则 Hash 无效，必须重算。由于目标值非常小，Hash 小于该值的机会极其渺茫，可能计算10亿次，才算中一次。这就是采矿如此之慢的根本原因。</li></ul><p>如果两个人同时向区块链写入数据，也就是说，同时有两个区块加入，因为它们都连着前一个区块，就形成了分叉。这时应该采纳哪一个区块呢？现在的规则是，新节点总是采用最长的那条区块链。如果区块链有分叉，将看哪个分支在分叉点后面，先达到6个新区块（称为&quot;六次确认&quot;）。按照10分钟一个区块计算，一小时就可以确认。</p><p>区块链作为无人管理的分布式数据库，从2009年开始已经运行了8年，没有出现大的问题。这证明它是可行的。但是，为了保证数据的可靠性，区块链也有自己的代价。一是效率，数据写入区块链，最少要等待十分钟，所有节点都同步数据，则需要更多的时间；二是能耗，区块的生成需要矿工进行无数无意义的计算，这是非常耗费能源的。</p><p>目前，区块链最大的应用场景（可能也是唯一的应用场景），就是以比特币为代表的加密货币。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;区块链（英语：blockchain 或 block chain）是用分布式数据库识别、传播和记载信息的智能化对等网络, 也称为价值互联网。中本聪在2008年，于《比特币白皮书》中提出“区块链”概念，并在2009年创立了比特币社会网络，开发出第一个区块，即“创世区块”。本文根据阮一峰老师的&lt;a href=&quot;http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html&quot;&gt;区块链入门教程&lt;/a&gt;整理并解释一下区块链到底是什么，有何特别之处。&lt;/p&gt;</summary>
    
    
    
    <category term="Wiki" scheme="http://saili.science/categories/Wiki/"/>
    
    
    <category term="Blockchain" scheme="http://saili.science/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>不平衡数据</title>
    <link href="http://saili.science/unbalanced-data/"/>
    <id>http://saili.science/unbalanced-data/</id>
    <published>2018-01-19T04:30:08.000Z</published>
    <updated>2018-03-23T12:25:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>在机器学习中，常常会遇到样本比例不平衡的问题，如对于一个二分类问题，正负样本的比例是 10:1。这种现象往往是由于本身数据来源决定的，如信用卡的征信问题中往往就是正样本居多。样本比例不平衡往往会带来不少问题，但是实际获取的数据又往往是不平衡的，因此本文主要讨论面对样本不平衡时的解决方法。</p><span id="more"></span><p>样本不平衡往往会导致模型对样本数较多的分类造成过拟合，即总是将样本分到了样本数较多的分类中；除此之外，一个典型的问题就是 <a href="https://en.wikipedia.org/wiki/Accuracy_paradox">Accuracy Paradox</a>，这个问题指的是模型的对样本预测的准确率很高，但是模型的泛化能力差。其原因是模型将大多数的样本都归类为样本数较多的那一类。</p><p>针对样本的不平衡问题，有以下几种常见的解决思路：</p><blockquote><p><a href="http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/">8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset</a><br><a href="https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set">In classification, how do you handle an unbalanced training set?</a></p></blockquote><h1 id="搜集更多的数据">I. 搜集更多的数据</h1><p>搜集更多的数据，从而让正负样本的比例平衡，这种方法往往是最被忽视的方法，然而实际上，当搜集数据的代价不大时，这种方法是最有效的。</p><p>但是需要注意，当搜集数据的场景本来产生数据的比例就是不平衡时，这种方法并不能解决数据比例不平衡问题。</p><h1 id="改变评判指标">II. 改变评判指标</h1><p>改变评判指标，也就是不用准确率来评判和选择模型，原因就是我们上面提到的 Accuracy Paradox 问题。实际上有一些评判指标就是专门解决样本不平衡时的评判问题的，如准确率，召回率，F1值，ROC（AUC），Kappa 等。</p><p>根据这篇文章，ROC 曲线具有不随样本比例而改变的良好性质，因此能够在样本比例不平衡的情况下较好地反映出分类器的优劣。</p><p>关于评判指标更详细的内容可参考文章： <a href="http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/">Classification Accuracy is Not Enough: More Performance Measures You Can Use</a></p><h1 id="对数据进行采样">III. 对数据进行采样</h1><p>对数据采样可以有针对性地改变数据中样本的比例，采样一般有两种方式：over-sampling 和 under-sampling，前者是增加样本数较少的样本，其方式是直接复制原来的样本，而后者是减少样本数较多的样本，其方式是丢弃这些多余的样本。</p><p>通常来说，当总样本数目较多的时候考虑 under-sampling，而样本数数目较少的时候考虑 over-sampling。</p><p>关于数据采样更详细的内容可参考 <a href="http://www.jair.org/papers/paper953.html">Oversampling and undersampling in data analysis</a></p><h1 id="合成样本">IV. 合成样本</h1><p>合成样本(Synthetic Samples)是为了增加样本数目较少的那一类的样本，合成指的是通过组合已有的样本的各个 feature 从而产生新的样本。</p><p>一种最简单的方法就是从各个 feature 中随机选出一个已有值，然后拼接成一个新的样本，这种方法增加了样本数目较少的类别的样本数，作用与上面提到的 Over-sampling 方法一样，不同点在于上面的方法是单纯的复制样本，而这里则是拼接得到新的样本。</p><p>这类方法中的具有代表性的方法是 SMOTE（Synthetic Minority Over-sampling Technique），这个方法通过在相似样本中进行 feature 的随机选择并拼接出新的样本。</p><p>关于 SMOTE 更详细的信息可参考论文 <a href="http://www.jair.org/papers/paper953.html">SMOTE: Synthetic Minority Over-sampling Technique</a></p><h1 id="改变样本权重">V. 改变样本权重</h1><p>改变样本权重指的是增大样本数较少类别的样本的权重，当这样的样本被误分时，其损失值要乘上相应的权重，从而让分类器更加关注这一类数目较少的样本。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在机器学习中，常常会遇到样本比例不平衡的问题，如对于一个二分类问题，正负样本的比例是 10:1。这种现象往往是由于本身数据来源决定的，如信用卡的征信问题中往往就是正样本居多。样本比例不平衡往往会带来不少问题，但是实际获取的数据又往往是不平衡的，因此本文主要讨论面对样本不平衡时的解决方法。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://saili.science/categories/Research/"/>
    
    
    <category term="MachineLearning" scheme="http://saili.science/tags/MachineLearning/"/>
    
    <category term="UnbalancedData" scheme="http://saili.science/tags/UnbalancedData/"/>
    
  </entry>
  
</feed>
